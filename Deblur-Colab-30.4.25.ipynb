{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "bVV35ZRWhLT7"
      },
      "id": "bVV35ZRWhLT7"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Deblur"
      ],
      "metadata": {
        "id": "TvJtt9dz_pO7"
      },
      "id": "TvJtt9dz_pO7",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JPBrito0528/Deblur"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghLHtAoxgswn",
        "outputId": "7f735b4a-6ccf-4b50-f025-f22186d56592"
      },
      "id": "ghLHtAoxgswn",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deblur'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 289 (delta 5), reused 19 (delta 2), pack-reused 267 (from 1)\u001b[K\n",
            "Receiving objects: 100% (289/289), 397.39 MiB | 22.93 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-msssim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvhkrgzoOGyy",
        "outputId": "f6093196-bd71-4065-e57e-72c25399af1f"
      },
      "id": "CvhkrgzoOGyy",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-msssim in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch-msssim) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch-msssim) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch-msssim) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3\n",
        "!pip install imgaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRxdYaUSguJ6",
        "outputId": "f6f74a21-b552-4412-ee6d-4128e27e6e50"
      },
      "id": "WRxdYaUSguJ6",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.24.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.15.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug) (4.11.0.86)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.37.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.1.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (2.9.0.post0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchviz"
      ],
      "metadata": {
        "id": "qs4mR-wagvPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47424f5d-3f4b-4f07-ddd9-6a2a24c70593"
      },
      "id": "qs4mR-wagvPZ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.11/dist-packages (0.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Deblur')\n",
        "\n",
        "from pytorch_msssim import ssim\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchviz import make_dot\n",
        "import model\n",
        "from model import common\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from tkinter import filedialog\n",
        "import random\n",
        "from math import ceil, floor\n",
        "import pandas as pd\n",
        "from imgaug import augmenters as iaa\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VexlmkcWgwrY"
      },
      "id": "VexlmkcWgwrY",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "8Xv3KZbnhTZZ"
      },
      "id": "8Xv3KZbnhTZZ"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "10b89fb9",
      "metadata": {
        "id": "10b89fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "7c4d21bb-98d6-4837-c2bb-31d27ee41574"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-fcdaa03c57ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mbatch_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_corners_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             batch_inputs, batch_outputs, batch_corners = yield_training_batch(\n\u001b[0m\u001b[1;32m   1040\u001b[0m                 \u001b[0mbatch_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_corners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-24-fcdaa03c57ea>\u001b[0m in \u001b[0;36myield_training_batch\u001b[0;34m(img_file_list, corners_list)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcornerBR_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcornerBR_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PRE DEBUG OUTPT'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m960\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ],
      "source": [
        "\n",
        "# --------------------------\n",
        "# Helper function to display images in Colab\n",
        "def imshow_cv2(img, title=\"Image\", resize_factor=0.5):\n",
        "    \"\"\"Display an image using matplotlib instead of cv.imshow.\"\"\"\n",
        "    # Convert BGR (OpenCV format) to RGB for display with matplotlib\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "        img_disp = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    else:\n",
        "        img_disp = img\n",
        "    # Resize image for display if desired\n",
        "    if resize_factor != 1:\n",
        "        img_disp = cv.resize(img_disp, (0, 0), fx=resize_factor, fy=resize_factor)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(img_disp, cmap='gray' if len(img_disp.shape) == 2 else None)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def build_square_mask(corners_list, H, W, device):\n",
        "    \"\"\"\n",
        "    corners_list: [(TL_x,TL_y,TR_x,TR_y,BL_x,BL_y,BR_x,BR_y), …] length B\n",
        "    returns: mask [B,1,H,W], 1 inside the square, 0 outside\n",
        "    \"\"\"\n",
        "    B = len(corners_list)\n",
        "    masks = torch.zeros(B, 1, H, W, device=device)\n",
        "    for i, c in enumerate(corners_list):\n",
        "        xs = sorted(c[0::2]); ys = sorted(c[1::2])\n",
        "        # drop the extreme corners → inner square\n",
        "        x0 = max(int(xs[1]) + 1, 0)\n",
        "        x1 = min(int(xs[-2]) - 1, W)\n",
        "        y0 = max(int(ys[1]) + 1, 0)\n",
        "        y1 = min(int(ys[-2]) - 1, H)\n",
        "        if x1 > x0 and y1 > y0:\n",
        "            masks[i, 0, y0:y1, x0:x1] = 1.0\n",
        "    return masks\n",
        "# ----------------------------\n",
        "\n",
        "DEBUG=True\n",
        "TEST=False\n",
        "TRAIN=False\n",
        "TRAIN_TYPE = 4 # 0 = weighted ROI ; 1 = black inverted ROI ; 2 = traditional MSE ; 3 - binary output; 4 - SSIM\n",
        "DNN_TYPE = 0 # 0 = EDSR ; 1 = UNET\n",
        "\n",
        "IMG_WIDTH = int(1920/2)\n",
        "IMG_HEIGHT = int(1080/2)\n",
        "IMG_CHANNELS = 3\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "SOURCE_FOLDER = '/content/Deblur'\n",
        "#SOURCE_FOLDER = 'C:/Users/guilherme.franco/Documents/GAF/Estagio_Rui_Brito'\n",
        "training_history_filename = SOURCE_FOLDER+'/Results/log.csv'\n",
        "\n",
        "seed=420\n",
        "SPLIT = 0.895\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE=4\n",
        "LEARNING_RATE = 10e-5\n",
        "\n",
        "### Setup Dataset ###############################################################################################\n",
        "\n",
        "raw_df = pd.read_csv(SOURCE_FOLDER+'/Lens_Dataset/data.csv').sample(frac=1)  #(read and shuffle)\n",
        "\n",
        "raw_size = int(len(raw_df))\n",
        "\n",
        "train_df = raw_df.head(floor(int(raw_size*SPLIT)))\n",
        "train_size = int(len(train_df))\n",
        "\n",
        "val_df = raw_df.tail(ceil(int(raw_size*(1-SPLIT))))\n",
        "val_size = int(len(val_df))\n",
        "\n",
        "train_df = train_df.sample(frac=1)\n",
        "val_df = val_df.sample(frac=1)\n",
        "\n",
        "# ── build lists of IDs + corner‐tuples for training & val ──\n",
        "all_ids         = raw_df['ID'].astype(str).tolist()\n",
        "all_corners     = raw_df[[\n",
        "    'cornerTL_x','cornerTL_y',\n",
        "    'cornerTR_x','cornerTR_y',\n",
        "    'cornerBL_x','cornerBL_y',\n",
        "    'cornerBR_x','cornerBR_y'\n",
        "]].values.tolist()\n",
        "\n",
        "train_img_list     = all_ids[:train_size]\n",
        "train_corners_list = all_corners[:train_size]\n",
        "val_img_list       = all_ids[train_size:]\n",
        "val_corners_list   = all_corners[train_size:]\n",
        "# ───────────────────────────────────────────────────────\n",
        "\n",
        "#################################################################################################################\n",
        "\n",
        "def yield_training_batch(img_file_list, corners_list):\n",
        "\n",
        "    batch_size = len(img_file_list)\n",
        "\n",
        "    input_images = []\n",
        "    output_images = []\n",
        "    batch_corners = []\n",
        "\n",
        "    for f in range(0,batch_size):\n",
        "\n",
        "        # Read image from list and convert to array\n",
        "        input_image_path = SOURCE_FOLDER+'/Lens_Dataset/INPUTS/'+str(img_file_list[f])+'.png'\n",
        "        output_image_path = SOURCE_FOLDER+'/Lens_Dataset/OUTPUTS/'+str(img_file_list[f])+'.png'\n",
        "\n",
        "        input_image = cv.imread(input_image_path)\n",
        "        output_image = cv.imread(output_image_path)\n",
        "\n",
        "        cornerTL_x = corners_list[f][0]\n",
        "        cornerTL_y = corners_list[f][1]\n",
        "        cornerTR_x = corners_list[f][2]\n",
        "        cornerTR_y = corners_list[f][3]\n",
        "        cornerBL_x = corners_list[f][4]\n",
        "        cornerBL_y = corners_list[f][5]\n",
        "        cornerBR_x = corners_list[f][6]\n",
        "        cornerBR_y = corners_list[f][7]\n",
        "\n",
        "\n",
        "        if DEBUG:\n",
        "            debug_img = output_image.copy()\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.imshow('PRE DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n",
        "\n",
        "\n",
        "        #generate random vector to determine which augmentations to perform\n",
        "        R = []\n",
        "        for r in range(0,7):\n",
        "            if DEBUG:\n",
        "                R.append(0)\n",
        "            else:\n",
        "                rn = random.random()\n",
        "                R.append(rn)\n",
        "\n",
        "        #======ZOOM AND CROP OR NOT?======#\n",
        "\n",
        "        if R[0] < 0.3:\n",
        "\n",
        "            aspect_ratio = input_image.shape[1]/input_image.shape[0]\n",
        "            target_ratio = IMG_WIDTH/IMG_HEIGHT\n",
        "            height_center = int(input_image.shape[0]/2)\n",
        "            width_center = int(input_image.shape[1]/2)\n",
        "\n",
        "            if aspect_ratio > IMG_WIDTH/IMG_HEIGHT:\n",
        "                target_width = int(input_image.shape[0]*target_ratio)\n",
        "                input_image = input_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n",
        "                output_image = output_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n",
        "\n",
        "            elif aspect_ratio < IMG_WIDTH/IMG_HEIGHT:\n",
        "                target_height = int(input_image.shape[1]*target_ratio)\n",
        "                input_image = input_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n",
        "                output_image = output_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n",
        "\n",
        "            rn = random.uniform(1,1)    #how much to zoom in\n",
        "\n",
        "            crop_w = floor(IMG_WIDTH*rn)    #how much to crop\n",
        "            crop_h = floor(IMG_HEIGHT*rn)\n",
        "\n",
        "            w_space = IMG_WIDTH - crop_w    #how much space is left\n",
        "            h_space = IMG_HEIGHT - crop_h\n",
        "\n",
        "            random_center_x = int(crop_w/2) + random.randint(0,w_space)     #center of the zoom/crop\n",
        "            random_center_y = int(crop_h/2) + random.randint(0,h_space)\n",
        "\n",
        "            #crops according to random parameters and resizes to desired input/output size\n",
        "            input_image = input_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n",
        "            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n",
        "            output_image = output_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n",
        "            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_NEAREST)\n",
        "\n",
        "\n",
        "            # TODO: estas contas provavelmente estão mal, pelo que 'desabilitei o random crop e zoom'\n",
        "            cornerTL_x = (cornerTL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerTL_y = (cornerTL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "            cornerTR_x = (cornerTR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerTR_y = (cornerTR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "            cornerBL_x = (cornerBL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerBL_y = (cornerBL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "            cornerBR_x = (cornerBR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerBR_y = (cornerBR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "\n",
        "        else:\n",
        "\n",
        "            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n",
        "            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n",
        "\n",
        "        #======FLIP OR NOT?======#\n",
        "\n",
        "        #Flip Horizontaly\n",
        "        if R[1] < 0.5:\n",
        "            input_image = cv.flip(input_image, 1)\n",
        "            output_image = cv.flip(output_image, 1)\n",
        "            cornerTL_x = (IMG_WIDTH) - cornerTL_x\n",
        "            cornerTR_x = (IMG_WIDTH) - cornerTR_x\n",
        "            cornerBL_x = (IMG_WIDTH) - cornerBL_x\n",
        "            cornerBR_x = (IMG_WIDTH) - cornerBR_x\n",
        "\n",
        "        #Flip Verticaly\n",
        "        if R[2] < 0.5:\n",
        "            input_image = cv.flip(input_image, 0)\n",
        "            output_image = cv.flip(output_image, 0)\n",
        "            cornerTL_y = (IMG_HEIGHT) - cornerTL_y\n",
        "            cornerTR_y = (IMG_HEIGHT) - cornerTR_y\n",
        "            cornerBL_y = (IMG_HEIGHT) - cornerBL_y\n",
        "            cornerBR_y = (IMG_HEIGHT) - cornerBR_y\n",
        "\n",
        "        #Color Shift\n",
        "        if R[3] < 0.3:\n",
        "            seq = iaa.Sequential([iaa.MultiplyHueAndSaturation((0.8, 1.2), per_channel=True)])\n",
        "            input_image = seq.augment_image(input_image)\n",
        "            output_image = seq.augment_image(output_image)\n",
        "\n",
        "        #Random Simplex Noise Blobs\n",
        "        # if R[4] < 0.3:\n",
        "        #     seq = iaa.SimplexNoiseAlpha( first=iaa.Multiply(mul = (0.6,1.4),per_channel=True),per_channel=True)\n",
        "        #     input_image = seq.augment_image(input_image)\n",
        "        #     output_image = seq.augment_image(output_image)\n",
        "\n",
        "        #Now we have to work in [0,1] instead of [0,255]\n",
        "        input_image = input_image/255.0\n",
        "        output_image = output_image/255.0\n",
        "\n",
        "        # Gaussian Blur\n",
        "        # if R[5] < 0.3:\n",
        "        #     input_image = cv.GaussianBlur(input_image,(5,5),0)\n",
        "\n",
        "        #Gaussian Noise\n",
        "        # if R[6] < 0:#0.2:\n",
        "        #     mean = 0\n",
        "        #     var = 0.001\n",
        "        #     sigma = var**0.5\n",
        "        #     gauss = np.random.normal(mean,sigma,(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n",
        "        #     gauss = gauss.reshape(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "        #     input_image = input_image + gauss\n",
        "\n",
        "        if DEBUG:\n",
        "            debug_img = output_image.copy()\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.imshow('DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n",
        "            cv.waitKey()\n",
        "\n",
        "        input_images.append(input_image)\n",
        "        output_images.append(output_image)\n",
        "        batch_corners.append((cornerTL_x,cornerTL_y,cornerTR_x,cornerTR_y,cornerBL_x,cornerBL_y,cornerBR_x,cornerBR_y))\n",
        "\n",
        "    input_images_np = np.array(input_images)\n",
        "    output_images_np = np.array(output_images)\n",
        "\n",
        "    if len(input_images) == 0:\n",
        "        # no valid images this batch\n",
        "        return None, None, []\n",
        "\n",
        "    # stack → (B, H, W, C)\n",
        "    input_np  = np.stack(input_images,  axis=0).astype(np.float32)\n",
        "    output_np = np.stack(output_images, axis=0).astype(np.float32)\n",
        "\n",
        "    # one‑shot tensor conversion + permute → (B, C, H, W)\n",
        "    input_tensor  = torch.from_numpy(input_np).permute(0, 3, 1, 2).cuda()\n",
        "    output_tensor = torch.from_numpy(output_np).permute(0, 3, 1, 2).cuda()\n",
        "\n",
        "    return input_tensor, output_tensor, batch_corners\n",
        "\n",
        "def yield_training_batch_black_BG(img_file_list, corners_list):\n",
        "    batch_size = len(img_file_list)\n",
        "    input_images = []\n",
        "    output_images = []\n",
        "    batch_corners = []\n",
        "\n",
        "    for f in range(batch_size):\n",
        "        try:\n",
        "            # Build paths and load images\n",
        "            input_image_path = SOURCE_FOLDER + '/Lens_Dataset/INPUTS/' + str(img_file_list[f]) + '.png'\n",
        "            output_image_path = SOURCE_FOLDER + '/Lens_Dataset/OUTPUTS/' + str(img_file_list[f]) + '.png'\n",
        "            input_image = cv.imread(input_image_path)\n",
        "            output_image = cv.imread(output_image_path)\n",
        "\n",
        "            # Check if image loading failed; if so, skip this image.\n",
        "            if input_image is None or output_image is None:\n",
        "                print(\"Skipping image\", img_file_list[f], \"- failed to load one or both images.\")\n",
        "                continue\n",
        "\n",
        "            # Extract corner coordinates\n",
        "            cornerTL_x = corners_list[f][0]\n",
        "            cornerTL_y = corners_list[f][1]\n",
        "            cornerTR_x = corners_list[f][2]\n",
        "            cornerTR_y = corners_list[f][3]\n",
        "            cornerBL_x = corners_list[f][4]\n",
        "            cornerBL_y = corners_list[f][5]\n",
        "            cornerBR_x = corners_list[f][6]\n",
        "            cornerBR_y = corners_list[f][7]\n",
        "\n",
        "            # (Optional debugging display omitted if not needed)\n",
        "\n",
        "            # Generate random vector for augmentation decisions\n",
        "            R = []\n",
        "            for r in range(7):\n",
        "                # You can remove DEBUG-related conditions if not required.\n",
        "                R.append(random.random())\n",
        "\n",
        "            # ====== ZOOM AND CROP OR NOT? ====== #\n",
        "            if R[0] < 0.3:\n",
        "                aspect_ratio = input_image.shape[1] / input_image.shape[0]\n",
        "                target_ratio = IMG_WIDTH / IMG_HEIGHT\n",
        "                height_center = int(input_image.shape[0] / 2)\n",
        "                width_center = int(input_image.shape[1] / 2)\n",
        "\n",
        "                if aspect_ratio > target_ratio:\n",
        "                    target_width = int(input_image.shape[0] * target_ratio)\n",
        "                    input_image = input_image[:, width_center - floor(target_width / 2):width_center + floor(target_width / 2)]\n",
        "                    output_image = output_image[:, width_center - floor(target_width / 2):width_center + floor(target_width / 2)]\n",
        "                elif aspect_ratio < target_ratio:\n",
        "                    target_height = int(input_image.shape[1] / target_ratio)\n",
        "                    input_image = input_image[height_center - floor(target_height / 2):height_center + floor(target_height / 2), :]\n",
        "                    output_image = output_image[height_center - floor(target_height / 2):height_center + floor(target_height / 2), :]\n",
        "\n",
        "                rn = random.uniform(1, 1)  # how much to zoom in\n",
        "                crop_w = floor(IMG_WIDTH * rn)\n",
        "                crop_h = floor(IMG_HEIGHT * rn)\n",
        "                w_space = IMG_WIDTH - crop_w\n",
        "                h_space = IMG_HEIGHT - crop_h\n",
        "\n",
        "                random_center_x = int(crop_w / 2) + random.randint(0, w_space)\n",
        "                random_center_y = int(crop_h / 2) + random.randint(0, h_space)\n",
        "\n",
        "                # Crop according to random parameters and resize to desired size\n",
        "                input_image = input_image[random_center_y - int(crop_h / 2):random_center_y + int(crop_h / 2),\n",
        "                                          random_center_x - int(crop_w / 2):random_center_x + int(crop_w / 2)]\n",
        "                input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_CUBIC)\n",
        "                output_image = output_image[random_center_y - int(crop_h / 2):random_center_y + int(crop_h / 2),\n",
        "                                            random_center_x - int(crop_w / 2):random_center_x + int(crop_w / 2)]\n",
        "                output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_NEAREST)\n",
        "\n",
        "                # Adjust corner coordinates (adjust these calculations as needed)\n",
        "                cornerTL_x = (cornerTL_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n",
        "                cornerTL_y = (cornerTL_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n",
        "                cornerTR_x = (cornerTR_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n",
        "                cornerTR_y = (cornerTR_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n",
        "                cornerBL_x = (cornerBL_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n",
        "                cornerBL_y = (cornerBL_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n",
        "                cornerBR_x = (cornerBR_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n",
        "                cornerBR_y = (cornerBR_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n",
        "\n",
        "            else:\n",
        "                input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_CUBIC)\n",
        "                output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_CUBIC)\n",
        "\n",
        "            # ====== FLIP OR NOT? ====== #\n",
        "            if R[1] < 0.5:\n",
        "                input_image = cv.flip(input_image, 1)\n",
        "                output_image = cv.flip(output_image, 1)\n",
        "                cornerTL_x = IMG_WIDTH - cornerTL_x\n",
        "                cornerTR_x = IMG_WIDTH - cornerTR_x\n",
        "                cornerBL_x = IMG_WIDTH - cornerBL_x\n",
        "                cornerBR_x = IMG_WIDTH - cornerBR_x\n",
        "\n",
        "            if R[2] < 0.5:\n",
        "                input_image = cv.flip(input_image, 0)\n",
        "                output_image = cv.flip(output_image, 0)\n",
        "                cornerTL_y = IMG_HEIGHT - cornerTL_y\n",
        "                cornerTR_y = IMG_HEIGHT - cornerTR_y\n",
        "                cornerBL_y = IMG_HEIGHT - cornerBL_y\n",
        "                cornerBR_y = IMG_HEIGHT - cornerBR_y\n",
        "\n",
        "            if R[3] < 0.3:\n",
        "                seq = iaa.Sequential([iaa.MultiplyHueAndSaturation((0.8, 1.2), per_channel=True)])\n",
        "                input_image = seq.augment_image(input_image)\n",
        "                output_image = seq.augment_image(output_image)\n",
        "\n",
        "            # Convert pixel range from [0,255] to [0,1]\n",
        "            input_image = input_image / 255.0\n",
        "            output_image = output_image / 255.0\n",
        "\n",
        "            sorted_x = np.sort((cornerTL_x, cornerBL_x, cornerTR_x, cornerBR_x))\n",
        "            sorted_y = np.sort((cornerTL_y, cornerBL_y, cornerTR_y, cornerBR_y))\n",
        "            min_x = int(sorted_x[1]) + 10\n",
        "            max_x = int(sorted_x[-2]) - 10\n",
        "            min_y = int(sorted_y[1]) + 10\n",
        "            max_y = int(sorted_y[-2]) - 10\n",
        "\n",
        "            cv.rectangle(output_image, (0, 0), (IMG_WIDTH, min_y), (0, 0, 0), -1)\n",
        "            cv.rectangle(output_image, (0, max_y), (IMG_WIDTH, IMG_HEIGHT), (0, 0, 0), -1)\n",
        "            cv.rectangle(output_image, (0, 0), (min_x, IMG_HEIGHT), (0, 0, 0), -1)\n",
        "            cv.rectangle(output_image, (max_x, 0), (IMG_WIDTH, IMG_HEIGHT), (0, 0, 0), -1)\n",
        "\n",
        "            # (Optional debugging display omitted if not needed)\n",
        "\n",
        "            # Append processed images and adjusted corners to lists\n",
        "            input_images.append(input_image)\n",
        "            output_images.append(output_image)\n",
        "            batch_corners.append((cornerTL_x, cornerTL_y,\n",
        "                                  cornerTR_x, cornerTR_y,\n",
        "                                  cornerBL_x, cornerBL_y,\n",
        "                                  cornerBR_x, cornerBR_y))\n",
        "\n",
        "        except Exception as e:\n",
        "            # If an error occurs processing an image, skip to the next image.\n",
        "            continue\n",
        "\n",
        "    # If no valid images were processed, return None for batch inputs/outputs\n",
        "    if len(input_images) == 0:\n",
        "        return None, None, []\n",
        "\n",
        "    # Convert lists to torch tensors and rearrange dimensions to [B, C, H, W]\n",
        "    input_images_tensor = torch.Tensor(np.array(input_images)).permute(0, 3, 1, 2)\n",
        "    output_images_tensor = torch.Tensor(np.array(output_images)).permute(0, 3, 1, 2)\n",
        "    return input_images_tensor.cuda(), output_images_tensor.cuda(), batch_corners\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def yield_training_batch_binary(img_file_list, corners_list):\n",
        "\n",
        "    batch_size = len(img_file_list)\n",
        "\n",
        "    input_images = []\n",
        "    output_images = []\n",
        "    batch_corners = []\n",
        "\n",
        "    for f in range(0,batch_size):\n",
        "\n",
        "        # Read image from list and convert to array\n",
        "        input_image_path = SOURCE_FOLDER+'/Lens_Dataset/INPUTS/'+str(img_file_list[f])+'.png'\n",
        "        output_image_path = SOURCE_FOLDER+'/Lens_Dataset/OUTPUTS/'+str(img_file_list[f])+'.png'\n",
        "\n",
        "        input_image = cv.imread(input_image_path)\n",
        "        output_image = cv.imread(output_image_path)\n",
        "\n",
        "        cornerTL_x = corners_list[f][0]\n",
        "        cornerTL_y = corners_list[f][1]\n",
        "        cornerTR_x = corners_list[f][2]\n",
        "        cornerTR_y = corners_list[f][3]\n",
        "        cornerBL_x = corners_list[f][4]\n",
        "        cornerBL_y = corners_list[f][5]\n",
        "        cornerBR_x = corners_list[f][6]\n",
        "        cornerBR_y = corners_list[f][7]\n",
        "\n",
        "\n",
        "        if DEBUG:\n",
        "            debug_img = output_image.copy()\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.imshow('PRE DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n",
        "\n",
        "\n",
        "        #generate random vector to determine which augmentations to perform\n",
        "        R = []\n",
        "        for r in range(0,7):\n",
        "            if DEBUG:\n",
        "                R.append(0)\n",
        "            else:\n",
        "                rn = random.random()\n",
        "                R.append(rn)\n",
        "\n",
        "        #======ZOOM AND CROP OR NOT?======#\n",
        "\n",
        "        if R[0] < 0.3:\n",
        "\n",
        "            aspect_ratio = input_image.shape[1]/input_image.shape[0]\n",
        "            target_ratio = IMG_WIDTH/IMG_HEIGHT\n",
        "            height_center = int(input_image.shape[0]/2)\n",
        "            width_center = int(input_image.shape[1]/2)\n",
        "\n",
        "            if aspect_ratio > IMG_WIDTH/IMG_HEIGHT:\n",
        "                target_width = int(input_image.shape[0]*target_ratio)\n",
        "                input_image = input_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n",
        "                output_image = output_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n",
        "\n",
        "            elif aspect_ratio < IMG_WIDTH/IMG_HEIGHT:\n",
        "                target_height = int(input_image.shape[1]*target_ratio)\n",
        "                input_image = input_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n",
        "                output_image = output_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n",
        "\n",
        "            rn = random.uniform(1,1)    #how much to zoom in\n",
        "\n",
        "            crop_w = floor(IMG_WIDTH*rn)    #how much to crop\n",
        "            crop_h = floor(IMG_HEIGHT*rn)\n",
        "\n",
        "            w_space = IMG_WIDTH - crop_w    #how much space is left\n",
        "            h_space = IMG_HEIGHT - crop_h\n",
        "\n",
        "            random_center_x = int(crop_w/2) + random.randint(0,w_space)     #center of the zoom/crop\n",
        "            random_center_y = int(crop_h/2) + random.randint(0,h_space)\n",
        "\n",
        "            #crops according to random parameters and resizes to desired input/output size\n",
        "            input_image = input_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n",
        "            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n",
        "            output_image = output_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n",
        "            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_NEAREST)\n",
        "\n",
        "\n",
        "            # TODO: estas contas provavelmente estão mal, pelo que 'desabilitei o random crop e zoom'\n",
        "            cornerTL_x = (cornerTL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerTL_y = (cornerTL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "            cornerTR_x = (cornerTR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerTR_y = (cornerTR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "            cornerBL_x = (cornerBL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerBL_y = (cornerBL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "            cornerBR_x = (cornerBR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n",
        "            cornerBR_y = (cornerBR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n",
        "\n",
        "        else:\n",
        "\n",
        "            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n",
        "            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n",
        "\n",
        "\n",
        "\n",
        "        #======FLIP OR NOT?======#\n",
        "\n",
        "        #Flip Horizontaly\n",
        "        if R[1] < 0.5:\n",
        "            input_image = cv.flip(input_image, 1)\n",
        "            output_image = cv.flip(output_image, 1)\n",
        "            cornerTL_x = (IMG_WIDTH) - cornerTL_x\n",
        "            cornerTR_x = (IMG_WIDTH) - cornerTR_x\n",
        "            cornerBL_x = (IMG_WIDTH) - cornerBL_x\n",
        "            cornerBR_x = (IMG_WIDTH) - cornerBR_x\n",
        "\n",
        "        #Flip Verticaly\n",
        "        if R[2] < 0.5:\n",
        "            input_image = cv.flip(input_image, 0)\n",
        "            output_image = cv.flip(output_image, 0)\n",
        "            cornerTL_y = (IMG_HEIGHT) - cornerTL_y\n",
        "            cornerTR_y = (IMG_HEIGHT) - cornerTR_y\n",
        "            cornerBL_y = (IMG_HEIGHT) - cornerBL_y\n",
        "            cornerBR_y = (IMG_HEIGHT) - cornerBR_y\n",
        "\n",
        "        #Color Shift\n",
        "        if R[3] < 0.3:\n",
        "            seq = iaa.Sequential([iaa.MultiplyHueAndSaturation((0.8, 1.2), per_channel=True)])\n",
        "            input_image = seq.augment_image(input_image)\n",
        "            output_image = seq.augment_image(output_image)\n",
        "\n",
        "        #Random Simplex Noise Blobs\n",
        "        # if R[4] < 0.3:\n",
        "        #     seq = iaa.SimplexNoiseAlpha( first=iaa.Multiply(mul = (0.6,1.4),per_channel=True),per_channel=True)\n",
        "        #     input_image = seq.augment_image(input_image)\n",
        "        #     output_image = seq.augment_image(output_image)\n",
        "\n",
        "        #Now we have to work in [0,1] instead of [0,255]\n",
        "        input_image = input_image/255.0\n",
        "        output_image = output_image/255.0\n",
        "\n",
        "        # Gaussian Blur\n",
        "        # if R[5] < 0.3:\n",
        "        #     input_image = cv.GaussianBlur(input_image,(5,5),0)\n",
        "\n",
        "        #Gaussian Noise\n",
        "        # if R[6] < 0:#0.2:\n",
        "        #     mean = 0\n",
        "        #     var = 0.001\n",
        "        #     sigma = var**0.5\n",
        "        #     gauss = np.random.normal(mean,sigma,(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n",
        "        #     gauss = gauss.reshape(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "        #     input_image = input_image + gauss\n",
        "\n",
        "        sorted_x = np.sort((cornerTL_x,cornerBL_x,cornerTR_x,cornerBR_x))\n",
        "        sorted_y = np.sort((cornerTL_y,cornerBL_y,cornerTR_y,cornerBR_y))\n",
        "\n",
        "        # find the second largest/smallest of the x and y values, and give some manouvering margin to ensure the are no edges\n",
        "        min_x = int(sorted_x[1])  + 10\n",
        "        max_x = int(sorted_x[-2]) - 10\n",
        "        min_y = int(sorted_y[1])  + 10\n",
        "        max_y = int(sorted_y[-2]) - 10\n",
        "\n",
        "        #min_x = int(min(cornerTL_x,cornerBL_x,cornerTR_x,cornerBR_x))\n",
        "        #max_x = int(max(cornerTL_x,cornerBL_x,cornerTR_x,cornerBR_x))\n",
        "        #min_y = int(min(cornerTL_y,cornerBL_y,cornerTR_y,cornerBR_y))\n",
        "        #max_y = int(max(cornerTL_y,cornerBL_y,cornerTR_y,cornerBR_y))\n",
        "\n",
        "        cv.rectangle(output_image,(0,0),(IMG_WIDTH,IMG_HEIGHT),(255,255,255),-1)\n",
        "        cv.rectangle(output_image,(0,0),(IMG_WIDTH,min_y),(0,0,0),-1)\n",
        "        cv.rectangle(output_image,(0,max_y),(IMG_WIDTH,IMG_HEIGHT),(0,0,0),-1)\n",
        "        cv.rectangle(output_image,(0,0),(min_x,IMG_HEIGHT),(0,0,0),-1)\n",
        "        cv.rectangle(output_image,(max_x,0),(IMG_WIDTH,IMG_HEIGHT),(0,0,0),-1)\n",
        "\n",
        "\n",
        "        if DEBUG:\n",
        "            debug_img = output_image.copy()\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n",
        "            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n",
        "\n",
        "            cv.imshow('DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n",
        "            cv.waitKey()\n",
        "\n",
        "        output_image = cv.cvtColor(output_image.astype(np.uint8),cv.COLOR_BGR2GRAY)\n",
        "        output_image = np.expand_dims(output_image,axis=2)\n",
        "\n",
        "        input_images.append(input_image)\n",
        "        output_images.append(output_image)\n",
        "        batch_corners.append((cornerTL_x,cornerTL_y,cornerTR_x,cornerTR_y,cornerBL_x,cornerBL_y,cornerBR_x,cornerBR_y))\n",
        "\n",
        "    input_images_np  = np.stack(input_images,  axis=0)\n",
        "    output_images_np = np.stack(output_images, axis=0)\n",
        "\n",
        "    if input_images_np.ndim != 4:\n",
        "      print(\"Skipping image with ID {img_file_list[f]} because one or both files were not found.\")\n",
        "\n",
        "    else:\n",
        "      input_tensor  = torch.from_numpy(input_np).permute(0, 3, 1, 2).cuda()\n",
        "      output_tensor = torch.from_numpy(output_np).permute(0, 3, 1, 2).cuda()\n",
        "\n",
        "\n",
        "    return input_images.cuda(), output_images.cuda(), batch_corners\n",
        "\n",
        "class EDSR(torch.nn.Module):\n",
        "    def __init__(self, conv=common.default_conv):\n",
        "        super(EDSR, self).__init__()\n",
        "\n",
        "        rgb_range = 1.0\n",
        "        n_resblocks = 5\n",
        "        if DNN_TYPE==0:\n",
        "            n_feats=3\n",
        "            n_output_feats=3\n",
        "            self.n_colors = 3\n",
        "        else:\n",
        "            n_feats=1\n",
        "            n_output_feats=1\n",
        "            self.n_colors = 3\n",
        "\n",
        "        kernel_size = 3\n",
        "        scale = 1\n",
        "        act = torch.nn.ReLU(True)\n",
        "        self.url = None\n",
        "        self.sub_mean = common.MeanShift(rgb_range)\n",
        "        self.add_mean = common.MeanShift(rgb_range, sign=1)\n",
        "\n",
        "        self.res_scale = 1\n",
        "\n",
        "        # define head module\n",
        "        m_head = [conv(self.n_colors, n_feats, kernel_size)]\n",
        "\n",
        "        # define body module\n",
        "        m_body = [\n",
        "            common.ResBlock(\n",
        "                conv, n_feats, kernel_size, act=act, res_scale=self.res_scale\n",
        "            ) for _ in range(n_resblocks)\n",
        "        ]\n",
        "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
        "\n",
        "        # define tail module\n",
        "        m_tail = [\n",
        "            common.Upsampler(conv, scale, n_output_feats, act=False),\n",
        "            conv(n_feats, self.n_colors, kernel_size)\n",
        "        ]\n",
        "\n",
        "        self.head = torch.nn.Sequential(*m_head)\n",
        "        self.body = torch.nn.Sequential(*m_body)\n",
        "        self.tail = torch.nn.Sequential(*m_tail)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sub_mean(x)\n",
        "        x = self.head(x)\n",
        "\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "\n",
        "        #x = self.tail(res)\n",
        "        x = self.add_mean(res)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def load_state_dict(self, state_dict, strict=True):\n",
        "        own_state = self.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name in own_state:\n",
        "                if isinstance(param, torch.nn.Parameter):\n",
        "                    param = param.data\n",
        "                try:\n",
        "                    own_state[name].copy_(param)\n",
        "                except Exception:\n",
        "                    if name.find('tail') == -1:\n",
        "                        raise RuntimeError('While copying the parameter named {}, '\n",
        "                                           'whose dimensions in the model are {} and '\n",
        "                                           'whose dimensions in the checkpoint are {}.'\n",
        "                                           .format(name, own_state[name].size(), param.size()))\n",
        "            elif strict:\n",
        "                if name.find('tail') == -1:\n",
        "                    raise KeyError('unexpected key \"{}\" in state_dict'\n",
        "                                   .format(name))\n",
        "\n",
        "class EDSR_binary(torch.nn.Module):\n",
        "    def __init__(self, conv=common.default_conv):\n",
        "        super(EDSR_binary, self).__init__()\n",
        "\n",
        "        rgb_range = 1.0\n",
        "        n_resblocks = 5\n",
        "        if DNN_TYPE==0:\n",
        "            n_feats=3\n",
        "            n_output_feats=3\n",
        "            self.n_colors = 3\n",
        "        else:\n",
        "            n_feats=1\n",
        "            n_output_feats=1\n",
        "            self.n_colors = 3\n",
        "\n",
        "        kernel_size = 3\n",
        "        scale = 1\n",
        "        act = torch.nn.ReLU(True)\n",
        "        self.url = None\n",
        "        self.sub_mean = common.MeanShift(rgb_range)\n",
        "        self.add_mean = common.MeanShift(rgb_range, sign=1)\n",
        "        self.collapse = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1)\n",
        "\n",
        "        self.res_scale = 1\n",
        "\n",
        "        # define head module\n",
        "        m_head = [conv(self.n_colors, n_feats, kernel_size)]\n",
        "\n",
        "        # define body module\n",
        "        m_body = [\n",
        "            common.ResBlock(\n",
        "                conv, n_feats, kernel_size, act=act, res_scale=self.res_scale\n",
        "            ) for _ in range(n_resblocks)\n",
        "        ]\n",
        "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
        "\n",
        "        # define tail module\n",
        "        m_tail = [\n",
        "            common.Upsampler(conv, scale, n_output_feats, act=False),\n",
        "            conv(n_feats, self.n_colors, kernel_size)\n",
        "        ]\n",
        "\n",
        "        self.head = torch.nn.Sequential(*m_head)\n",
        "        self.body = torch.nn.Sequential(*m_body)\n",
        "        self.tail = torch.nn.Sequential(*m_tail)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sub_mean(x)\n",
        "        x = self.head(x)\n",
        "\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "\n",
        "        #x = self.tail(res)\n",
        "        x = self.add_mean(res)\n",
        "        x=self.collapse(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def load_state_dict(self, state_dict, strict=True):\n",
        "        own_state = self.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name in own_state:\n",
        "                if isinstance(param, torch.nn.Parameter):\n",
        "                    param = param.data\n",
        "                try:\n",
        "                    own_state[name].copy_(param)\n",
        "                except Exception:\n",
        "                    if name.find('tail') == -1:\n",
        "                        raise RuntimeError('While copying the parameter named {}, '\n",
        "                                           'whose dimensions in the model are {} and '\n",
        "                                           'whose dimensions in the checkpoint are {}.'\n",
        "                                           .format(name, own_state[name].size(), param.size()))\n",
        "            elif strict:\n",
        "                if name.find('tail') == -1:\n",
        "                    raise KeyError('unexpected key \"{}\" in state_dict'\n",
        "                                   .format(name))\n",
        "\n",
        "FILTER_SIZE = 128\n",
        "PADDING = 1\n",
        "\n",
        "class DoubleConv(torch.nn.Module):\n",
        "    \"\"\"(Conv => BN => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "\n",
        "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(torch.nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=[4,8, 16, 32]):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Downsampling path\n",
        "        self.downs = torch.nn.ModuleList()\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "\n",
        "        # Upsampling path\n",
        "        self.ups = torch.nn.ModuleList()\n",
        "        self.upconvs = torch.nn.ModuleList()\n",
        "\n",
        "        rev_features = features[::-1]\n",
        "        for feature in rev_features:\n",
        "            self.upconvs.append(torch.nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "            self.ups.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        # Final output layer\n",
        "        if DNN_TYPE==0:\n",
        "            self.final_conv = torch.nn.Conv2d(features[0], 3, kernel_size=1)\n",
        "        else:\n",
        "            self.final_conv = torch.nn.Conv2d(features[0], 1, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder / Down path\n",
        "        x1 = self.downs[0](x)              # [B, 64, H, W]\n",
        "        x2 = self.downs[1](self.pool(x1))  # [B, 128, H/2, W/2]\n",
        "        x3 = self.downs[2](self.pool(x2))  # [B, 256, H/4, W/4]\n",
        "        x4 = self.downs[3](self.pool(x3))  # [B, 512, H/8, W/8]\n",
        "\n",
        "        # Bottleneck\n",
        "        x5 = self.bottleneck(self.pool(x4))  # [B, 1024, H/16, W/16]\n",
        "\n",
        "        # Decoder / Up path\n",
        "        u4 = self.upconvs[0](x5)\n",
        "        if u4.shape != x4.shape:\n",
        "            u4 = torch.nn.functional.interpolate(u4, size=x4.shape[2:])\n",
        "        u4 = self.ups[0](torch.cat([x4, u4], dim=1))\n",
        "\n",
        "        u3 = self.upconvs[1](u4)\n",
        "        if u3.shape != x3.shape:\n",
        "            u3 = torch.nn.functional.interpolate(u3, size=x3.shape[2:])\n",
        "        u3 = self.ups[1](torch.cat([x3, u3], dim=1))\n",
        "\n",
        "        u2 = self.upconvs[2](u3)\n",
        "        if u2.shape != x2.shape:\n",
        "            u2 = torch.nn.functional.interpolate(u2, size=x2.shape[2:])\n",
        "        u2 = self.ups[2](torch.cat([x2, u2], dim=1))\n",
        "\n",
        "        u1 = self.upconvs[3](u2)\n",
        "        if u1.shape != x1.shape:\n",
        "            u1 = torch.nn.functional.interpolate(u1, size=x1.shape[2:])\n",
        "        u1 = self.ups[3](torch.cat([x1, u1], dim=1))\n",
        "\n",
        "        # Final output\n",
        "        return self.final_conv(u1)\n",
        "\n",
        "\n",
        "#======================================== LOSS FUNCTION ==============================================\n",
        "\n",
        "if DNN_TYPE==0:\n",
        "    if TRAIN_TYPE==3:\n",
        "        model=EDSR_binary()\n",
        "    else:\n",
        "        model=EDSR()\n",
        "else:\n",
        "    model=UNet()\n",
        "\n",
        "def _gaussian_window(window_size: int, sigma: float) -> torch.Tensor:\n",
        "    coords = torch.arange(window_size, dtype=torch.float)\n",
        "    coords -= (window_size - 1) / 2.0\n",
        "    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
        "    g /= g.sum()\n",
        "    return g\n",
        "\n",
        "def _create_window(window_size: int, channel: int, device, dtype) -> torch.Tensor:\n",
        "    # 1D Gaussian\n",
        "    _1d = _gaussian_window(window_size, sigma=1.5).to(device=device, dtype=dtype)\n",
        "    _2d = _1d.unsqueeze(1) @ _1d.unsqueeze(0)              # outer product → 2D kernel\n",
        "    _2d = _2d.unsqueeze(0).unsqueeze(0)                     # shape (1,1,ws,ws)\n",
        "    window = _2d.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        "\n",
        "class MaskedDeblurLoss(nn.Module):\n",
        "    def __init__(self, lambda_ssim=0.5):\n",
        "        super().__init__()\n",
        "        self.lambda_ssim = lambda_ssim\n",
        "\n",
        "    def forward(self, pred, target, corners):\n",
        "        # pred, target: [B,3,H,W], in [0,1]\n",
        "        B, C, H, W = pred.shape\n",
        "        device = pred.device\n",
        "\n",
        "        # a) build mask\n",
        "        mask = build_square_mask(corners, H, W, device)     # [B,1,H,W]\n",
        "\n",
        "        # b) masked MSE\n",
        "        diff2 = (pred - target).pow(2).mean(dim=1, keepdim=True)  # [B,1,H,W]\n",
        "        mse_num = (diff2 * mask).sum()\n",
        "        mse_den = mask.sum().clamp(min=1.0)\n",
        "        loss_mse = mse_num / mse_den\n",
        "\n",
        "        # c) masked SSIM\n",
        "        # we multiply by mask so that SSIM only “sees” the square\n",
        "        # ssim() returns one scalar per batch if size_average=True\n",
        "        loss_ssim = 1 - ssim(\n",
        "            pred * mask,\n",
        "            target * mask,\n",
        "            data_range=1.0,\n",
        "            size_average=True\n",
        "        )\n",
        "\n",
        "        return loss_mse + self.lambda_ssim * loss_ssim\n",
        "\n",
        "\n",
        "class MSE_Crop_Loss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSE_Crop_Loss, self).__init__()\n",
        "    def forward(self,pred, target, corners):\n",
        "\n",
        "        crop_score = 0\n",
        "\n",
        "        for b in range(len(corners)):\n",
        "            corners_x = corners[b][0:8:2]\n",
        "            corners_y = corners[b][1:8:2]\n",
        "            min_x = min(corners_x)\n",
        "            max_x = max(corners_x)\n",
        "            min_y = min(corners_y)\n",
        "            max_y = max(corners_y)\n",
        "\n",
        "            if min_x<0:\n",
        "                min_x=0\n",
        "            if min_y<0:\n",
        "                min_y=0\n",
        "            if max_x<0:\n",
        "                max_x=0\n",
        "            if max_y<0:\n",
        "                max_y=0\n",
        "            if min_x>IMG_WIDTH:\n",
        "                min_x=IMG_WIDTH\n",
        "            if min_y>IMG_HEIGHT:\n",
        "                min_y=IMG_HEIGHT\n",
        "            if max_x>IMG_WIDTH:\n",
        "                max_x=IMG_WIDTH\n",
        "            if max_y>IMG_HEIGHT:\n",
        "                max_y=IMG_HEIGHT\n",
        "\n",
        "            cropped_tgt = torchvision.transforms.functional.crop(target[b],int(min_y),int(min_x),int(max_y-min_y), int(max_x-min_x))\n",
        "            cropped_pred = torchvision.transforms.functional.crop(pred[b],int(min_y),int(min_x),int(max_y-min_y), int(max_x-min_x))\n",
        "            #cropped_tgt = target[b][min_x:max_x,min_y:max_y]\n",
        "            #cropped_pred = pred[b][min_x:max_x,min_y:max_y]\n",
        "            crop_score += torch.nn.functional.mse_loss(cropped_pred,cropped_tgt)\n",
        "            #crop_score = np.square(np.subtract(cropped_pred,cropped_tgt)).mean()\n",
        "\n",
        "        score = torch.nn.functional.mse_loss(pred,target)\n",
        "\n",
        "        crop_score = crop_score / len(corners)\n",
        "        return 1-(0.9*crop_score + 0.1*score)\n",
        "\n",
        "x = torch.randn(1,3,1920, 1080)\n",
        "y = model(x)\n",
        "\n",
        "aux = y[0,:,:,:].cpu().detach().numpy()*255\n",
        "aux = aux.astype(np.uint8)\n",
        "aux = np.transpose(aux, (1,2,0))\n",
        "\n",
        "make_dot(y.mean(), params=dict(model.named_parameters())).render('Debulr_Model', format=\"png\")\n",
        "\n",
        "model_image = cv.imread('Debulr_Model.png')\n",
        "cv.imwrite(SOURCE_FOLDER+'/Results/Deblur_Model.png',model_image)\n",
        "\n",
        "model= torch.nn.DataParallel(model)\n",
        "model.to('cuda')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "if TRAIN_TYPE == 4:\n",
        "    loss_function = MaskedDeblurLoss(lambda_ssim=0.5)\n",
        "elif TRAIN_TYPE == 3:\n",
        "    loss_function = nn.BCEWithLogitsLoss()\n",
        "elif TRAIN_TYPE == 0:\n",
        "    loss_function = MSE_Crop_Loss()   # your existing crop‐MSE\n",
        "else:\n",
        "    loss_function = nn.MSELoss()\n",
        "\n",
        "# Create Log file\n",
        "with open(training_history_filename, \"w\") as csv_file:\n",
        "    progress_string = 'EPOCH,LOSS,TRAIN_SCORE,VAL_SCORE/n'\n",
        "    csv_file.write(progress_string)\n",
        "\n",
        "\n",
        "best_train_score = 0.0\n",
        "\n",
        "if TRAIN:\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        running_train_score = 0.0\n",
        "        running_val_score = 0.0\n",
        "\n",
        "        # count how many batches we actually processed\n",
        "        n_train_batches = 0\n",
        "        n_val_batches   = 0\n",
        "\n",
        "        # —————— training ——————\n",
        "        for start in range(0, len(train_img_list), BATCH_SIZE):\n",
        "            batch_ids     = train_img_list    [start : start + BATCH_SIZE]\n",
        "            batch_corners = train_corners_list[start : start + BATCH_SIZE]\n",
        "\n",
        "            batch_inputs, batch_outputs, batch_corners = yield_training_batch(\n",
        "                batch_ids, batch_corners\n",
        "            )\n",
        "            if batch_inputs is None:\n",
        "                continue\n",
        "\n",
        "            n_train_batches += 1\n",
        "            batch_preds = model(batch_inputs)\n",
        "            # compute loss exactly as you already do…\n",
        "            if TRAIN_TYPE in (0,4):\n",
        "                loss = loss_function(batch_preds, batch_outputs.cuda(), batch_corners)\n",
        "            else:\n",
        "                loss = loss_function(batch_preds, batch_outputs.cuda())\n",
        "\n",
        "            train_score = 1.0 - loss\n",
        "\n",
        "            # backprop…\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_train_score += train_score.item()\n",
        "\n",
        "        # —————— validation ——————\n",
        "        for start in range(0, len(val_img_list), BATCH_SIZE):\n",
        "            batch_ids     = val_img_list    [start : start + BATCH_SIZE]\n",
        "            batch_corners = val_corners_list[start : start + BATCH_SIZE]\n",
        "\n",
        "            batch_inputs, batch_outputs, batch_corners = yield_training_batch(\n",
        "                batch_ids, batch_corners\n",
        "            )\n",
        "            if batch_inputs is None:\n",
        "                continue\n",
        "\n",
        "            n_val_batches += 1\n",
        "            batch_preds = model(batch_inputs)\n",
        "            if TRAIN_TYPE in (0,4):\n",
        "                val_loss = loss_function(batch_preds, batch_outputs.cuda(), batch_corners)\n",
        "            else:\n",
        "                val_loss = loss_function(batch_preds, batch_outputs.cuda())\n",
        "            val_score = 1.0 - val_loss\n",
        "\n",
        "            running_val_score += val_score.item()\n",
        "\n",
        "        # —————— now compute **averages** ——————\n",
        "        avg_loss       = running_loss       / max(1, n_train_batches)\n",
        "        avg_train_score= running_train_score/ max(1, n_train_batches)\n",
        "        avg_val_score  = running_val_score  / max(1, n_val_batches)\n",
        "\n",
        "        print(f\"Epoch {epoch}  \"\n",
        "              f\"Avg Train Loss: {avg_loss:.4f}  \"\n",
        "              f\"Avg Train Score: {avg_train_score:.4f}  \"\n",
        "              f\"Avg Val Score: {avg_val_score:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "        # write epoch-level **averages** to CSV\n",
        "        with open(training_history_filename, \"a\") as csv_file:\n",
        "            progress_string = (\n",
        "                f\"{epoch},\"\n",
        "                f\"{avg_loss:.6f},\"\n",
        "                f\"{avg_train_score:.6f},\"\n",
        "                f\"{avg_val_score:.6f}\\n\"\n",
        "            )\n",
        "            csv_file.write(progress_string)\n",
        "\n",
        "        print('=========================================================')\n",
        "        print(f'Epoch {epoch}')\n",
        "        print(f'Avg Train Loss:    {avg_loss:.6f}')\n",
        "        print(f'Avg Train Score:   {avg_train_score:.6f}')\n",
        "        print(f'Avg Val   Score:   {avg_val_score:.6f}')\n",
        "        print('=========================================================')\n",
        "\n",
        "        if avg_train_score > best_train_score:\n",
        "            best_train_score = avg_train_score\n",
        "            model_name = 'Best_Deblur_model'\n",
        "            # rebuild a fresh model instance and load weights\n",
        "            if DNN_TYPE == 0:\n",
        "                model_to_save = EDSR_binary() if TRAIN_TYPE == 3 else EDSR()\n",
        "            else:\n",
        "                model_to_save = UNet()\n",
        "            model_to_save.load_state_dict(model.module.state_dict())\n",
        "            model_to_save.to('cuda')\n",
        "            model_scripted = torch.jit.script(model_to_save)\n",
        "            model_scripted.save(f\"{SOURCE_FOLDER}/Results/{model_name}.pt\")\n",
        "\n",
        "print('DONE')\n",
        "\n",
        "\n",
        "if TEST:\n",
        "    # Load the best model from file (update path if necessary)\n",
        "    model_path = os.path.join(SOURCE_FOLDER, 'Results', '16.04.2025.pt')\n",
        "    model_instance = torch.load(model_path,weights_only=False)\n",
        "    model_instance.to('cuda')\n",
        "    model_instance.eval()\n",
        "    test_dir = os.path.join(SOURCE_FOLDER, 'Lens_Dataset', 'INPUTS')  # Set your test directory\n",
        "    filelist = [f for f in os.listdir(test_dir) if f.endswith('.png')]\n",
        "\n",
        "    # Display predictions for up to 10 random test images\n",
        "    for i in range(min(10, len(filelist))):\n",
        "        r = random.randrange(0, len(filelist))\n",
        "        frame = cv.imread(os.path.join(test_dir, filelist[r]))\n",
        "        # Resize and normalize for network input\n",
        "        frame = cv.resize(frame, (1920, 1080)) / 255.0\n",
        "        frame_T = np.transpose(frame, (2, 0, 1))\n",
        "        np_tensor = np.expand_dims(frame_T, axis=0).astype(np.float32)\n",
        "        input_tensor = torch.tensor(np_tensor).cuda()\n",
        "        with torch.no_grad():\n",
        "            preds = model_instance(input_tensor)\n",
        "        # For SSIM mode, apply sigmoid to force outputs in [0,1]\n",
        "        if TRAIN_TYPE == 4:\n",
        "            preds = torch.sigmoid(preds)\n",
        "        aux = preds[0, :, :, :].cpu().detach().numpy() * 255\n",
        "        aux = aux.astype(np.uint8)\n",
        "        output_image = np.transpose(aux, (1, 2, 0))\n",
        "        imshow_cv2(output_image, title=f\"Prediction for {filelist[r]}\", resize_factor=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  /content/Deblur/Results/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BGpqnAM5Tbo",
        "outputId": "2989fd05-e7f7-4b00-884d-c759e1d88db7"
      },
      "id": "7BGpqnAM5Tbo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/Deblur/Results/': No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bVV35ZRWhLT7"
      ],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}