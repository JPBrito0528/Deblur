{"cells":[{"cell_type":"markdown","source":["# Initialization"],"metadata":{"id":"bVV35ZRWhLT7"},"id":"bVV35ZRWhLT7"},{"cell_type":"code","source":["!rm -rf Deblur"],"metadata":{"id":"TvJtt9dz_pO7","executionInfo":{"status":"ok","timestamp":1745229690692,"user_tz":-60,"elapsed":147,"user":{"displayName":"João Brito","userId":"12639566270386605316"}}},"id":"TvJtt9dz_pO7","execution_count":1,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/JPBrito0528/Deblur"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghLHtAoxgswn","executionInfo":{"status":"ok","timestamp":1745229710745,"user_tz":-60,"elapsed":20048,"user":{"displayName":"João Brito","userId":"12639566270386605316"}},"outputId":"06ec9288-a62f-47ab-88f1-f6310ad90bbd"},"id":"ghLHtAoxgswn","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Deblur'...\n","remote: Enumerating objects: 286, done.\u001b[K\n","remote: Counting objects: 100% (19/19), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 286 (delta 4), reused 17 (delta 2), pack-reused 267 (from 1)\u001b[K\n","Receiving objects: 100% (286/286), 397.38 MiB | 22.08 MiB/s, done.\n","Resolving deltas: 100% (7/7), done.\n"]}]},{"cell_type":"code","source":["!pip install pytorch-msssim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvhkrgzoOGyy","executionInfo":{"status":"ok","timestamp":1745229773264,"user_tz":-60,"elapsed":62517,"user":{"displayName":"João Brito","userId":"12639566270386605316"}},"outputId":"2a3a502a-2153-44d0-d8e4-9c9f0ec4a0e9"},"id":"CvhkrgzoOGyy","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-msssim\n","  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch-msssim) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pytorch-msssim)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pytorch-msssim)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pytorch-msssim)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch-msssim)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch-msssim)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch-msssim)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch-msssim)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch-msssim)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch-msssim)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch-msssim)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch-msssim) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch-msssim) (3.0.2)\n","Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-msssim\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-msssim-1.0.0\n"]}]},{"cell_type":"code","source":["!pip install numpy==1.24.3\n","!pip install imgaug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":939},"id":"WRxdYaUSguJ6","executionInfo":{"status":"ok","timestamp":1745229781993,"user_tz":-60,"elapsed":8727,"user":{"displayName":"João Brito","userId":"12639566270386605316"}},"outputId":"752e216f-3f14-46bd-c5c5-9735861c1a97"},"id":"WRxdYaUSguJ6","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.24.3\n","  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n","albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n","blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n","albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n","pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.24.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"5d07076310fc4e2cbf85c9a31a98f534"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting imgaug\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.17.0)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.24.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.14.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug) (11.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug) (3.10.0)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug) (0.25.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug) (4.11.0.86)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.37.0)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.1.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (3.4.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (2025.3.30)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (0.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (2.8.2)\n","Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: imgaug\n","Successfully installed imgaug-0.4.0\n"]}]},{"cell_type":"code","source":["pip install torchviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qs4mR-wagvPZ","executionInfo":{"status":"ok","timestamp":1745229791724,"user_tz":-60,"elapsed":2109,"user":{"displayName":"João Brito","userId":"12639566270386605316"}},"outputId":"86ec5146-8584-4f24-e851-3ef8d9ab74d3"},"id":"qs4mR-wagvPZ","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchviz in /usr/local/lib/python3.11/dist-packages (0.0.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/Deblur')\n","\n","from pytorch_msssim import ms_ssim\n","from google.colab.patches import cv2_imshow\n","import torch\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms.functional as TF\n","from torchviz import make_dot\n","import model\n","from model import common\n","import cv2 as cv\n","import numpy as np\n","import os\n","import torch.nn as nn\n","from tkinter import filedialog\n","import random\n","from math import ceil, floor\n","import pandas as pd\n","from imgaug import augmenters as iaa\n","import matplotlib.pyplot as plt"],"metadata":{"id":"VexlmkcWgwrY","executionInfo":{"status":"ok","timestamp":1745229800762,"user_tz":-60,"elapsed":7081,"user":{"displayName":"João Brito","userId":"12639566270386605316"}}},"id":"VexlmkcWgwrY","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"8Xv3KZbnhTZZ"},"id":"8Xv3KZbnhTZZ"},{"cell_type":"code","execution_count":null,"id":"10b89fb9","metadata":{"id":"10b89fb9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a78665c5-db47-43ac-d6f8-c1de3e05c1ad","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================\n","Epoch 0\n","Loss 7.682298183441162\n","Train Score 14.317704200744629\n","Validation Score 1.8278212547302246\n","=========================================================\n","=========================================================\n","Epoch 1\n","Loss 7.416843891143799\n","Train Score 14.583157539367676\n","Validation Score 1.91563081741333\n","=========================================================\n","=========================================================\n","Epoch 2\n","Loss 7.202683925628662\n","Train Score 14.797316551208496\n","Validation Score 1.8325625658035278\n","=========================================================\n","=========================================================\n","Epoch 3\n","Loss 6.939722537994385\n","Train Score 15.060276985168457\n","Validation Score 1.8994220495224\n","=========================================================\n","=========================================================\n","Epoch 4\n","Loss 6.9605865478515625\n","Train Score 15.039414405822754\n","Validation Score 2.1288437843322754\n","=========================================================\n","=========================================================\n","Epoch 5\n","Loss 6.448334693908691\n","Train Score 15.551666259765625\n","Validation Score 1.8521783351898193\n","=========================================================\n","=========================================================\n","Epoch 6\n","Loss 6.561953067779541\n","Train Score 15.43804931640625\n","Validation Score 1.9245989322662354\n","=========================================================\n","=========================================================\n","Epoch 7\n","Loss 6.245787620544434\n","Train Score 15.75421142578125\n","Validation Score 1.922702670097351\n","=========================================================\n","=========================================================\n","Epoch 8\n","Loss 6.421470642089844\n","Train Score 15.578529357910156\n","Validation Score 1.8698700666427612\n","=========================================================\n"]}],"source":["# --------------------------\n","# Helper function to display images in Colab\n","def imshow_cv2(img, title=\"Image\", resize_factor=0.5):\n","    \"\"\"Display an image using matplotlib instead of cv.imshow.\"\"\"\n","    # Convert BGR (OpenCV format) to RGB for display with matplotlib\n","    if len(img.shape) == 3 and img.shape[2] == 3:\n","        img_disp = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n","    else:\n","        img_disp = img\n","    # Resize image for display if desired\n","    if resize_factor != 1:\n","        img_disp = cv.resize(img_disp, (0, 0), fx=resize_factor, fy=resize_factor)\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.imshow(img_disp, cmap='gray' if len(img_disp.shape) == 2 else None)\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()\n","# ----------------------------\n","\n","DEBUG=False\n","TEST=False\n","TRAIN=True\n","TRAIN_TYPE = 4 # 0 = weighted ROI ; 1 = black inverted ROI ; 2 = traditional MSE ; 3 - binary output; 4 - SSIM\n","DNN_TYPE = 0 # 0 = EDSR ; 1 = UNET\n","\n","IMG_WIDTH = int(1920/2)\n","IMG_HEIGHT = int(1080/2)\n","IMG_CHANNELS = 3\n","input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n","\n","SOURCE_FOLDER = '/content/Deblur'\n","#SOURCE_FOLDER = 'C:/Users/guilherme.franco/Documents/GAF/Estagio_Rui_Brito'\n","training_history_filename = SOURCE_FOLDER+'/Results/log.csv'\n","\n","seed=420\n","SPLIT = 0.895\n","EPOCHS = 500\n","BATCH_SIZE=4\n","LEARNING_RATE = 10e-5\n","\n","### Setup Dataset ###############################################################################################\n","\n","raw_df = pd.read_csv(SOURCE_FOLDER+'/Lens_Dataset/data.csv').sample(frac=1)  #(read and shuffle)\n","\n","raw_size = int(len(raw_df))\n","\n","train_df = raw_df.head(floor(int(raw_size*SPLIT)))\n","train_size = int(len(train_df))\n","\n","val_df = raw_df.tail(ceil(int(raw_size*(1-SPLIT))))\n","val_size = int(len(val_df))\n","\n","train_df = train_df.sample(frac=1)\n","val_df = val_df.sample(frac=1)\n","\n","#################################################################################################################\n","\n","def yield_training_batch(img_file_list, corners_list):\n","\n","    batch_size = len(img_file_list)\n","\n","    input_images = []\n","    output_images = []\n","    batch_corners = []\n","\n","    for f in range(0,batch_size):\n","\n","        # Read image from list and convert to array\n","        input_image_path = SOURCE_FOLDER+'/Lens_Dataset/INPUTS/'+str(img_file_list[f])+'.png'\n","        output_image_path = SOURCE_FOLDER+'/Lens_Dataset/OUTPUTS/'+str(img_file_list[f])+'.png'\n","\n","        input_image = cv.imread(input_image_path)\n","        output_image = cv.imread(output_image_path)\n","\n","        cornerTL_x = corners_list[f][0]\n","        cornerTL_y = corners_list[f][1]\n","        cornerTR_x = corners_list[f][2]\n","        cornerTR_y = corners_list[f][3]\n","        cornerBL_x = corners_list[f][4]\n","        cornerBL_y = corners_list[f][5]\n","        cornerBR_x = corners_list[f][6]\n","        cornerBR_y = corners_list[f][7]\n","\n","\n","        if DEBUG:\n","            debug_img = output_image.copy()\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n","\n","            cv.imshow('PRE DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n","\n","\n","        #generate random vector to determine which augmentations to perform\n","        R = []\n","        for r in range(0,7):\n","            if DEBUG:\n","                R.append(0)\n","            else:\n","                rn = random.random()\n","                R.append(rn)\n","\n","        #======ZOOM AND CROP OR NOT?======#\n","\n","        if R[0] < 0.3:\n","\n","            aspect_ratio = input_image.shape[1]/input_image.shape[0]\n","            target_ratio = IMG_WIDTH/IMG_HEIGHT\n","            height_center = int(input_image.shape[0]/2)\n","            width_center = int(input_image.shape[1]/2)\n","\n","            if aspect_ratio > IMG_WIDTH/IMG_HEIGHT:\n","                target_width = int(input_image.shape[0]*target_ratio)\n","                input_image = input_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n","                output_image = output_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n","\n","            elif aspect_ratio < IMG_WIDTH/IMG_HEIGHT:\n","                target_height = int(input_image.shape[1]*target_ratio)\n","                input_image = input_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n","                output_image = output_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n","\n","            rn = random.uniform(1,1)    #how much to zoom in\n","\n","            crop_w = floor(IMG_WIDTH*rn)    #how much to crop\n","            crop_h = floor(IMG_HEIGHT*rn)\n","\n","            w_space = IMG_WIDTH - crop_w    #how much space is left\n","            h_space = IMG_HEIGHT - crop_h\n","\n","            random_center_x = int(crop_w/2) + random.randint(0,w_space)     #center of the zoom/crop\n","            random_center_y = int(crop_h/2) + random.randint(0,h_space)\n","\n","            #crops according to random parameters and resizes to desired input/output size\n","            input_image = input_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n","            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n","            output_image = output_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n","            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_NEAREST)\n","\n","\n","            # TODO: estas contas provavelmente estão mal, pelo que 'desabilitei o random crop e zoom'\n","            cornerTL_x = (cornerTL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerTL_y = (cornerTL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","            cornerTR_x = (cornerTR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerTR_y = (cornerTR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","            cornerBL_x = (cornerBL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerBL_y = (cornerBL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","            cornerBR_x = (cornerBR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerBR_y = (cornerBR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","\n","        else:\n","\n","            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n","            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n","\n","        #======FLIP OR NOT?======#\n","\n","        #Flip Horizontaly\n","        if R[1] < 0.5:\n","            input_image = cv.flip(input_image, 1)\n","            output_image = cv.flip(output_image, 1)\n","            cornerTL_x = (IMG_WIDTH) - cornerTL_x\n","            cornerTR_x = (IMG_WIDTH) - cornerTR_x\n","            cornerBL_x = (IMG_WIDTH) - cornerBL_x\n","            cornerBR_x = (IMG_WIDTH) - cornerBR_x\n","\n","        #Flip Verticaly\n","        if R[2] < 0.5:\n","            input_image = cv.flip(input_image, 0)\n","            output_image = cv.flip(output_image, 0)\n","            cornerTL_y = (IMG_HEIGHT) - cornerTL_y\n","            cornerTR_y = (IMG_HEIGHT) - cornerTR_y\n","            cornerBL_y = (IMG_HEIGHT) - cornerBL_y\n","            cornerBR_y = (IMG_HEIGHT) - cornerBR_y\n","\n","        #Color Shift\n","        if R[3] < 0.3:\n","            seq = iaa.Sequential([iaa.MultiplyHueAndSaturation((0.8, 1.2), per_channel=True)])\n","            input_image = seq.augment_image(input_image)\n","            output_image = seq.augment_image(output_image)\n","\n","        #Random Simplex Noise Blobs\n","        # if R[4] < 0.3:\n","        #     seq = iaa.SimplexNoiseAlpha( first=iaa.Multiply(mul = (0.6,1.4),per_channel=True),per_channel=True)\n","        #     input_image = seq.augment_image(input_image)\n","        #     output_image = seq.augment_image(output_image)\n","\n","        #Now we have to work in [0,1] instead of [0,255]\n","        input_image = input_image/255.0\n","        output_image = output_image/255.0\n","\n","        # Gaussian Blur\n","        # if R[5] < 0.3:\n","        #     input_image = cv.GaussianBlur(input_image,(5,5),0)\n","\n","        #Gaussian Noise\n","        # if R[6] < 0:#0.2:\n","        #     mean = 0\n","        #     var = 0.001\n","        #     sigma = var**0.5\n","        #     gauss = np.random.normal(mean,sigma,(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n","        #     gauss = gauss.reshape(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n","        #     input_image = input_image + gauss\n","\n","        if DEBUG:\n","            debug_img = output_image.copy()\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n","\n","            cv.imshow('DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n","            cv.waitKey()\n","\n","        input_images.append(input_image)\n","        output_images.append(output_image)\n","        batch_corners.append((cornerTL_x,cornerTL_y,cornerTR_x,cornerTR_y,cornerBL_x,cornerBL_y,cornerBR_x,cornerBR_y))\n","\n","    input_images_np = np.array(input_images)\n","    output_images_np = np.array(output_images)\n","\n","    if len(input_images) == 0:\n","        # no valid images this batch\n","        return None, None, []\n","\n","    # stack → (B, H, W, C)\n","    input_np  = np.stack(input_images,  axis=0).astype(np.float32)\n","    output_np = np.stack(output_images, axis=0).astype(np.float32)\n","\n","    # one‑shot tensor conversion + permute → (B, C, H, W)\n","    input_tensor  = torch.from_numpy(input_np).permute(0, 3, 1, 2).cuda()\n","    output_tensor = torch.from_numpy(output_np).permute(0, 3, 1, 2).cuda()\n","\n","    return input_tensor, output_tensor, batch_corners\n","\n","def yield_training_batch_black_BG(img_file_list, corners_list):\n","    batch_size = len(img_file_list)\n","    input_images = []\n","    output_images = []\n","    batch_corners = []\n","\n","    for f in range(batch_size):\n","        try:\n","            # Build paths and load images\n","            input_image_path = SOURCE_FOLDER + '/Lens_Dataset/INPUTS/' + str(img_file_list[f]) + '.png'\n","            output_image_path = SOURCE_FOLDER + '/Lens_Dataset/OUTPUTS/' + str(img_file_list[f]) + '.png'\n","            input_image = cv.imread(input_image_path)\n","            output_image = cv.imread(output_image_path)\n","\n","            # Check if image loading failed; if so, skip this image.\n","            if input_image is None or output_image is None:\n","                print(\"Skipping image\", img_file_list[f], \"- failed to load one or both images.\")\n","                continue\n","\n","            # Extract corner coordinates\n","            cornerTL_x = corners_list[f][0]\n","            cornerTL_y = corners_list[f][1]\n","            cornerTR_x = corners_list[f][2]\n","            cornerTR_y = corners_list[f][3]\n","            cornerBL_x = corners_list[f][4]\n","            cornerBL_y = corners_list[f][5]\n","            cornerBR_x = corners_list[f][6]\n","            cornerBR_y = corners_list[f][7]\n","\n","            # (Optional debugging display omitted if not needed)\n","\n","            # Generate random vector for augmentation decisions\n","            R = []\n","            for r in range(7):\n","                # You can remove DEBUG-related conditions if not required.\n","                R.append(random.random())\n","\n","            # ====== ZOOM AND CROP OR NOT? ====== #\n","            if R[0] < 0.3:\n","                aspect_ratio = input_image.shape[1] / input_image.shape[0]\n","                target_ratio = IMG_WIDTH / IMG_HEIGHT\n","                height_center = int(input_image.shape[0] / 2)\n","                width_center = int(input_image.shape[1] / 2)\n","\n","                if aspect_ratio > target_ratio:\n","                    target_width = int(input_image.shape[0] * target_ratio)\n","                    input_image = input_image[:, width_center - floor(target_width / 2):width_center + floor(target_width / 2)]\n","                    output_image = output_image[:, width_center - floor(target_width / 2):width_center + floor(target_width / 2)]\n","                elif aspect_ratio < target_ratio:\n","                    target_height = int(input_image.shape[1] / target_ratio)\n","                    input_image = input_image[height_center - floor(target_height / 2):height_center + floor(target_height / 2), :]\n","                    output_image = output_image[height_center - floor(target_height / 2):height_center + floor(target_height / 2), :]\n","\n","                rn = random.uniform(1, 1)  # how much to zoom in\n","                crop_w = floor(IMG_WIDTH * rn)\n","                crop_h = floor(IMG_HEIGHT * rn)\n","                w_space = IMG_WIDTH - crop_w\n","                h_space = IMG_HEIGHT - crop_h\n","\n","                random_center_x = int(crop_w / 2) + random.randint(0, w_space)\n","                random_center_y = int(crop_h / 2) + random.randint(0, h_space)\n","\n","                # Crop according to random parameters and resize to desired size\n","                input_image = input_image[random_center_y - int(crop_h / 2):random_center_y + int(crop_h / 2),\n","                                          random_center_x - int(crop_w / 2):random_center_x + int(crop_w / 2)]\n","                input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_CUBIC)\n","                output_image = output_image[random_center_y - int(crop_h / 2):random_center_y + int(crop_h / 2),\n","                                            random_center_x - int(crop_w / 2):random_center_x + int(crop_w / 2)]\n","                output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_NEAREST)\n","\n","                # Adjust corner coordinates (adjust these calculations as needed)\n","                cornerTL_x = (cornerTL_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n","                cornerTL_y = (cornerTL_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n","                cornerTR_x = (cornerTR_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n","                cornerTR_y = (cornerTR_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n","                cornerBL_x = (cornerBL_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n","                cornerBL_y = (cornerBL_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n","                cornerBR_x = (cornerBR_x - (random_center_x - (IMG_WIDTH / 2))) * rn\n","                cornerBR_y = (cornerBR_y - (random_center_y - (IMG_HEIGHT / 2))) * rn\n","\n","            else:\n","                input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_CUBIC)\n","                output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv.INTER_CUBIC)\n","\n","            # ====== FLIP OR NOT? ====== #\n","            if R[1] < 0.5:\n","                input_image = cv.flip(input_image, 1)\n","                output_image = cv.flip(output_image, 1)\n","                cornerTL_x = IMG_WIDTH - cornerTL_x\n","                cornerTR_x = IMG_WIDTH - cornerTR_x\n","                cornerBL_x = IMG_WIDTH - cornerBL_x\n","                cornerBR_x = IMG_WIDTH - cornerBR_x\n","\n","            if R[2] < 0.5:\n","                input_image = cv.flip(input_image, 0)\n","                output_image = cv.flip(output_image, 0)\n","                cornerTL_y = IMG_HEIGHT - cornerTL_y\n","                cornerTR_y = IMG_HEIGHT - cornerTR_y\n","                cornerBL_y = IMG_HEIGHT - cornerBL_y\n","                cornerBR_y = IMG_HEIGHT - cornerBR_y\n","\n","            if R[3] < 0.3:\n","                seq = iaa.Sequential([iaa.MultiplyHueAndSaturation((0.8, 1.2), per_channel=True)])\n","                input_image = seq.augment_image(input_image)\n","                output_image = seq.augment_image(output_image)\n","\n","            # Convert pixel range from [0,255] to [0,1]\n","            input_image = input_image / 255.0\n","            output_image = output_image / 255.0\n","\n","            sorted_x = np.sort((cornerTL_x, cornerBL_x, cornerTR_x, cornerBR_x))\n","            sorted_y = np.sort((cornerTL_y, cornerBL_y, cornerTR_y, cornerBR_y))\n","            min_x = int(sorted_x[1]) + 10\n","            max_x = int(sorted_x[-2]) - 10\n","            min_y = int(sorted_y[1]) + 10\n","            max_y = int(sorted_y[-2]) - 10\n","\n","            cv.rectangle(output_image, (0, 0), (IMG_WIDTH, min_y), (0, 0, 0), -1)\n","            cv.rectangle(output_image, (0, max_y), (IMG_WIDTH, IMG_HEIGHT), (0, 0, 0), -1)\n","            cv.rectangle(output_image, (0, 0), (min_x, IMG_HEIGHT), (0, 0, 0), -1)\n","            cv.rectangle(output_image, (max_x, 0), (IMG_WIDTH, IMG_HEIGHT), (0, 0, 0), -1)\n","\n","            # (Optional debugging display omitted if not needed)\n","\n","            # Append processed images and adjusted corners to lists\n","            input_images.append(input_image)\n","            output_images.append(output_image)\n","            batch_corners.append((cornerTL_x, cornerTL_y,\n","                                  cornerTR_x, cornerTR_y,\n","                                  cornerBL_x, cornerBL_y,\n","                                  cornerBR_x, cornerBR_y))\n","\n","        except Exception as e:\n","            # If an error occurs processing an image, skip to the next image.\n","            continue\n","\n","    # If no valid images were processed, return None for batch inputs/outputs\n","    if len(input_images) == 0:\n","        return None, None, []\n","\n","    # Convert lists to torch tensors and rearrange dimensions to [B, C, H, W]\n","    input_images_tensor = torch.Tensor(np.array(input_images)).permute(0, 3, 1, 2)\n","    output_images_tensor = torch.Tensor(np.array(output_images)).permute(0, 3, 1, 2)\n","    return input_images_tensor.cuda(), output_images_tensor.cuda(), batch_corners\n","\n","\n","\n","\n","\n","def yield_training_batch_binary(img_file_list, corners_list):\n","\n","    batch_size = len(img_file_list)\n","\n","    input_images = []\n","    output_images = []\n","    batch_corners = []\n","\n","    for f in range(0,batch_size):\n","\n","        # Read image from list and convert to array\n","        input_image_path = SOURCE_FOLDER+'/Lens_Dataset/INPUTS/'+str(img_file_list[f])+'.png'\n","        output_image_path = SOURCE_FOLDER+'/Lens_Dataset/OUTPUTS/'+str(img_file_list[f])+'.png'\n","\n","        input_image = cv.imread(input_image_path)\n","        output_image = cv.imread(output_image_path)\n","\n","        cornerTL_x = corners_list[f][0]\n","        cornerTL_y = corners_list[f][1]\n","        cornerTR_x = corners_list[f][2]\n","        cornerTR_y = corners_list[f][3]\n","        cornerBL_x = corners_list[f][4]\n","        cornerBL_y = corners_list[f][5]\n","        cornerBR_x = corners_list[f][6]\n","        cornerBR_y = corners_list[f][7]\n","\n","\n","        if DEBUG:\n","            debug_img = output_image.copy()\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n","\n","            cv.imshow('PRE DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n","\n","\n","        #generate random vector to determine which augmentations to perform\n","        R = []\n","        for r in range(0,7):\n","            if DEBUG:\n","                R.append(0)\n","            else:\n","                rn = random.random()\n","                R.append(rn)\n","\n","        #======ZOOM AND CROP OR NOT?======#\n","\n","        if R[0] < 0.3:\n","\n","            aspect_ratio = input_image.shape[1]/input_image.shape[0]\n","            target_ratio = IMG_WIDTH/IMG_HEIGHT\n","            height_center = int(input_image.shape[0]/2)\n","            width_center = int(input_image.shape[1]/2)\n","\n","            if aspect_ratio > IMG_WIDTH/IMG_HEIGHT:\n","                target_width = int(input_image.shape[0]*target_ratio)\n","                input_image = input_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n","                output_image = output_image[0:input_image.shape[0], width_center-floor(target_width/2):width_center+floor(target_width/2)]\n","\n","            elif aspect_ratio < IMG_WIDTH/IMG_HEIGHT:\n","                target_height = int(input_image.shape[1]*target_ratio)\n","                input_image = input_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n","                output_image = output_image[height_center-floor(target_height/2):height_center+floor(target_height/2), 0:input_image.shape[1]]\n","\n","            rn = random.uniform(1,1)    #how much to zoom in\n","\n","            crop_w = floor(IMG_WIDTH*rn)    #how much to crop\n","            crop_h = floor(IMG_HEIGHT*rn)\n","\n","            w_space = IMG_WIDTH - crop_w    #how much space is left\n","            h_space = IMG_HEIGHT - crop_h\n","\n","            random_center_x = int(crop_w/2) + random.randint(0,w_space)     #center of the zoom/crop\n","            random_center_y = int(crop_h/2) + random.randint(0,h_space)\n","\n","            #crops according to random parameters and resizes to desired input/output size\n","            input_image = input_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n","            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n","            output_image = output_image[random_center_y-int(crop_h/2):random_center_y+int(crop_h/2),random_center_x-int(crop_w/2):random_center_x+int(crop_w/2)]\n","            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_NEAREST)\n","\n","\n","            # TODO: estas contas provavelmente estão mal, pelo que 'desabilitei o random crop e zoom'\n","            cornerTL_x = (cornerTL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerTL_y = (cornerTL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","            cornerTR_x = (cornerTR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerTR_y = (cornerTR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","            cornerBL_x = (cornerBL_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerBL_y = (cornerBL_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","            cornerBR_x = (cornerBR_x-(random_center_x - (IMG_WIDTH/2)))*rn\n","            cornerBR_y = (cornerBR_y-(random_center_y - (IMG_HEIGHT/2)))*rn\n","\n","        else:\n","\n","            input_image = cv.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n","            output_image = cv.resize(output_image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv.INTER_CUBIC)\n","\n","\n","\n","        #======FLIP OR NOT?======#\n","\n","        #Flip Horizontaly\n","        if R[1] < 0.5:\n","            input_image = cv.flip(input_image, 1)\n","            output_image = cv.flip(output_image, 1)\n","            cornerTL_x = (IMG_WIDTH) - cornerTL_x\n","            cornerTR_x = (IMG_WIDTH) - cornerTR_x\n","            cornerBL_x = (IMG_WIDTH) - cornerBL_x\n","            cornerBR_x = (IMG_WIDTH) - cornerBR_x\n","\n","        #Flip Verticaly\n","        if R[2] < 0.5:\n","            input_image = cv.flip(input_image, 0)\n","            output_image = cv.flip(output_image, 0)\n","            cornerTL_y = (IMG_HEIGHT) - cornerTL_y\n","            cornerTR_y = (IMG_HEIGHT) - cornerTR_y\n","            cornerBL_y = (IMG_HEIGHT) - cornerBL_y\n","            cornerBR_y = (IMG_HEIGHT) - cornerBR_y\n","\n","        #Color Shift\n","        if R[3] < 0.3:\n","            seq = iaa.Sequential([iaa.MultiplyHueAndSaturation((0.8, 1.2), per_channel=True)])\n","            input_image = seq.augment_image(input_image)\n","            output_image = seq.augment_image(output_image)\n","\n","        #Random Simplex Noise Blobs\n","        # if R[4] < 0.3:\n","        #     seq = iaa.SimplexNoiseAlpha( first=iaa.Multiply(mul = (0.6,1.4),per_channel=True),per_channel=True)\n","        #     input_image = seq.augment_image(input_image)\n","        #     output_image = seq.augment_image(output_image)\n","\n","        #Now we have to work in [0,1] instead of [0,255]\n","        input_image = input_image/255.0\n","        output_image = output_image/255.0\n","\n","        # Gaussian Blur\n","        # if R[5] < 0.3:\n","        #     input_image = cv.GaussianBlur(input_image,(5,5),0)\n","\n","        #Gaussian Noise\n","        # if R[6] < 0:#0.2:\n","        #     mean = 0\n","        #     var = 0.001\n","        #     sigma = var**0.5\n","        #     gauss = np.random.normal(mean,sigma,(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n","        #     gauss = gauss.reshape(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n","        #     input_image = input_image + gauss\n","\n","        sorted_x = np.sort((cornerTL_x,cornerBL_x,cornerTR_x,cornerBR_x))\n","        sorted_y = np.sort((cornerTL_y,cornerBL_y,cornerTR_y,cornerBR_y))\n","\n","        # find the second largest/smallest of the x and y values, and give some manouvering margin to ensure the are no edges\n","        min_x = int(sorted_x[1])  + 10\n","        max_x = int(sorted_x[-2]) - 10\n","        min_y = int(sorted_y[1])  + 10\n","        max_y = int(sorted_y[-2]) - 10\n","\n","        #min_x = int(min(cornerTL_x,cornerBL_x,cornerTR_x,cornerBR_x))\n","        #max_x = int(max(cornerTL_x,cornerBL_x,cornerTR_x,cornerBR_x))\n","        #min_y = int(min(cornerTL_y,cornerBL_y,cornerTR_y,cornerBR_y))\n","        #max_y = int(max(cornerTL_y,cornerBL_y,cornerTR_y,cornerBR_y))\n","\n","        cv.rectangle(output_image,(0,0),(IMG_WIDTH,IMG_HEIGHT),(255,255,255),-1)\n","        cv.rectangle(output_image,(0,0),(IMG_WIDTH,min_y),(0,0,0),-1)\n","        cv.rectangle(output_image,(0,max_y),(IMG_WIDTH,IMG_HEIGHT),(0,0,0),-1)\n","        cv.rectangle(output_image,(0,0),(min_x,IMG_HEIGHT),(0,0,0),-1)\n","        cv.rectangle(output_image,(max_x,0),(IMG_WIDTH,IMG_HEIGHT),(0,0,0),-1)\n","\n","\n","        if DEBUG:\n","            debug_img = output_image.copy()\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTL_x),int(cornerTL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerTR_x),int(cornerTR_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBL_x),int(cornerBL_y)),6,(255,255,255),-1)\n","\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),10,(0,0,0),-1)\n","            cv.circle(debug_img,(int(cornerBR_x),int(cornerBR_y)),6,(255,255,255),-1)\n","\n","            cv.imshow('DEBUG OUTPT',  cv.resize(debug_img,(960,720)))\n","            cv.waitKey()\n","\n","        output_image = cv.cvtColor(output_image.astype(np.uint8),cv.COLOR_BGR2GRAY)\n","        output_image = np.expand_dims(output_image,axis=2)\n","\n","        input_images.append(input_image)\n","        output_images.append(output_image)\n","        batch_corners.append((cornerTL_x,cornerTL_y,cornerTR_x,cornerTR_y,cornerBL_x,cornerBL_y,cornerBR_x,cornerBR_y))\n","\n","    input_images_np  = np.stack(input_images,  axis=0)\n","    output_images_np = np.stack(output_images, axis=0)\n","\n","    if input_images_np.ndim != 4:\n","      print(\"Skipping image with ID {img_file_list[f]} because one or both files were not found.\")\n","\n","    else:\n","      input_tensor  = torch.from_numpy(input_np).permute(0, 3, 1, 2).cuda()\n","      output_tensor = torch.from_numpy(output_np).permute(0, 3, 1, 2).cuda()\n","\n","\n","    return input_images.cuda(), output_images.cuda(), batch_corners\n","\n","class EDSR(torch.nn.Module):\n","    def __init__(self, conv=common.default_conv):\n","        super(EDSR, self).__init__()\n","\n","        rgb_range = 1.0\n","        n_resblocks = 5\n","        if DNN_TYPE==0:\n","            n_feats=3\n","            n_output_feats=3\n","            self.n_colors = 3\n","        else:\n","            n_feats=1\n","            n_output_feats=1\n","            self.n_colors = 3\n","\n","        kernel_size = 3\n","        scale = 1\n","        act = torch.nn.ReLU(True)\n","        self.url = None\n","        self.sub_mean = common.MeanShift(rgb_range)\n","        self.add_mean = common.MeanShift(rgb_range, sign=1)\n","\n","        self.res_scale = 1\n","\n","        # define head module\n","        m_head = [conv(self.n_colors, n_feats, kernel_size)]\n","\n","        # define body module\n","        m_body = [\n","            common.ResBlock(\n","                conv, n_feats, kernel_size, act=act, res_scale=self.res_scale\n","            ) for _ in range(n_resblocks)\n","        ]\n","        m_body.append(conv(n_feats, n_feats, kernel_size))\n","\n","        # define tail module\n","        m_tail = [\n","            common.Upsampler(conv, scale, n_output_feats, act=False),\n","            conv(n_feats, self.n_colors, kernel_size)\n","        ]\n","\n","        self.head = torch.nn.Sequential(*m_head)\n","        self.body = torch.nn.Sequential(*m_body)\n","        self.tail = torch.nn.Sequential(*m_tail)\n","\n","    def forward(self, x):\n","        x = self.sub_mean(x)\n","        x = self.head(x)\n","\n","        res = self.body(x)\n","        res += x\n","\n","        #x = self.tail(res)\n","        x = self.add_mean(res)\n","\n","        return x\n","\n","    def load_state_dict(self, state_dict, strict=True):\n","        own_state = self.state_dict()\n","        for name, param in state_dict.items():\n","            if name in own_state:\n","                if isinstance(param, torch.nn.Parameter):\n","                    param = param.data\n","                try:\n","                    own_state[name].copy_(param)\n","                except Exception:\n","                    if name.find('tail') == -1:\n","                        raise RuntimeError('While copying the parameter named {}, '\n","                                           'whose dimensions in the model are {} and '\n","                                           'whose dimensions in the checkpoint are {}.'\n","                                           .format(name, own_state[name].size(), param.size()))\n","            elif strict:\n","                if name.find('tail') == -1:\n","                    raise KeyError('unexpected key \"{}\" in state_dict'\n","                                   .format(name))\n","\n","class EDSR_binary(torch.nn.Module):\n","    def __init__(self, conv=common.default_conv):\n","        super(EDSR_binary, self).__init__()\n","\n","        rgb_range = 1.0\n","        n_resblocks = 5\n","        if DNN_TYPE==0:\n","            n_feats=3\n","            n_output_feats=3\n","            self.n_colors = 3\n","        else:\n","            n_feats=1\n","            n_output_feats=1\n","            self.n_colors = 3\n","\n","        kernel_size = 3\n","        scale = 1\n","        act = torch.nn.ReLU(True)\n","        self.url = None\n","        self.sub_mean = common.MeanShift(rgb_range)\n","        self.add_mean = common.MeanShift(rgb_range, sign=1)\n","        self.collapse = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1)\n","\n","        self.res_scale = 1\n","\n","        # define head module\n","        m_head = [conv(self.n_colors, n_feats, kernel_size)]\n","\n","        # define body module\n","        m_body = [\n","            common.ResBlock(\n","                conv, n_feats, kernel_size, act=act, res_scale=self.res_scale\n","            ) for _ in range(n_resblocks)\n","        ]\n","        m_body.append(conv(n_feats, n_feats, kernel_size))\n","\n","        # define tail module\n","        m_tail = [\n","            common.Upsampler(conv, scale, n_output_feats, act=False),\n","            conv(n_feats, self.n_colors, kernel_size)\n","        ]\n","\n","        self.head = torch.nn.Sequential(*m_head)\n","        self.body = torch.nn.Sequential(*m_body)\n","        self.tail = torch.nn.Sequential(*m_tail)\n","\n","    def forward(self, x):\n","        x = self.sub_mean(x)\n","        x = self.head(x)\n","\n","        res = self.body(x)\n","        res += x\n","\n","        #x = self.tail(res)\n","        x = self.add_mean(res)\n","        x=self.collapse(x)\n","\n","        return x\n","\n","    def load_state_dict(self, state_dict, strict=True):\n","        own_state = self.state_dict()\n","        for name, param in state_dict.items():\n","            if name in own_state:\n","                if isinstance(param, torch.nn.Parameter):\n","                    param = param.data\n","                try:\n","                    own_state[name].copy_(param)\n","                except Exception:\n","                    if name.find('tail') == -1:\n","                        raise RuntimeError('While copying the parameter named {}, '\n","                                           'whose dimensions in the model are {} and '\n","                                           'whose dimensions in the checkpoint are {}.'\n","                                           .format(name, own_state[name].size(), param.size()))\n","            elif strict:\n","                if name.find('tail') == -1:\n","                    raise KeyError('unexpected key \"{}\" in state_dict'\n","                                   .format(name))\n","\n","FILTER_SIZE = 128\n","PADDING = 1\n","\n","class DoubleConv(torch.nn.Module):\n","    \"\"\"(Conv => BN => ReLU) * 2\"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.double_conv = torch.nn.Sequential(\n","            torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(out_channels),\n","            torch.nn.ReLU(inplace=True),\n","\n","            torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(out_channels),\n","            torch.nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class UNet(torch.nn.Module):\n","    def __init__(self, in_channels=3, out_channels=3, features=[4,8, 16, 32]):\n","        super(UNet, self).__init__()\n","\n","        # Downsampling path\n","        self.downs = torch.nn.ModuleList()\n","        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Bottleneck\n","        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n","\n","        # Upsampling path\n","        self.ups = torch.nn.ModuleList()\n","        self.upconvs = torch.nn.ModuleList()\n","\n","        rev_features = features[::-1]\n","        for feature in rev_features:\n","            self.upconvs.append(torch.nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n","            self.ups.append(DoubleConv(feature * 2, feature))\n","\n","        # Final output layer\n","        if DNN_TYPE==0:\n","            self.final_conv = torch.nn.Conv2d(features[0], 3, kernel_size=1)\n","        else:\n","            self.final_conv = torch.nn.Conv2d(features[0], 1, kernel_size=1)\n","\n","\n","    def forward(self, x):\n","        # Encoder / Down path\n","        x1 = self.downs[0](x)              # [B, 64, H, W]\n","        x2 = self.downs[1](self.pool(x1))  # [B, 128, H/2, W/2]\n","        x3 = self.downs[2](self.pool(x2))  # [B, 256, H/4, W/4]\n","        x4 = self.downs[3](self.pool(x3))  # [B, 512, H/8, W/8]\n","\n","        # Bottleneck\n","        x5 = self.bottleneck(self.pool(x4))  # [B, 1024, H/16, W/16]\n","\n","        # Decoder / Up path\n","        u4 = self.upconvs[0](x5)\n","        if u4.shape != x4.shape:\n","            u4 = torch.nn.functional.interpolate(u4, size=x4.shape[2:])\n","        u4 = self.ups[0](torch.cat([x4, u4], dim=1))\n","\n","        u3 = self.upconvs[1](u4)\n","        if u3.shape != x3.shape:\n","            u3 = torch.nn.functional.interpolate(u3, size=x3.shape[2:])\n","        u3 = self.ups[1](torch.cat([x3, u3], dim=1))\n","\n","        u2 = self.upconvs[2](u3)\n","        if u2.shape != x2.shape:\n","            u2 = torch.nn.functional.interpolate(u2, size=x2.shape[2:])\n","        u2 = self.ups[2](torch.cat([x2, u2], dim=1))\n","\n","        u1 = self.upconvs[3](u2)\n","        if u1.shape != x1.shape:\n","            u1 = torch.nn.functional.interpolate(u1, size=x1.shape[2:])\n","        u1 = self.ups[3](torch.cat([x1, u1], dim=1))\n","\n","        # Final output\n","        return self.final_conv(u1)\n","\n","\n","#======================================== LOSS FUNCTION ==============================================\n","\n","if DNN_TYPE==0:\n","    if TRAIN_TYPE==3:\n","        model=EDSR_binary()\n","    else:\n","        model=EDSR()\n","else:\n","    model=UNet()\n","\n","def _gaussian_window(window_size: int, sigma: float) -> torch.Tensor:\n","    coords = torch.arange(window_size, dtype=torch.float)\n","    coords -= (window_size - 1) / 2.0\n","    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n","    g /= g.sum()\n","    return g\n","\n","def _create_window(window_size: int, channel: int, device, dtype) -> torch.Tensor:\n","    # 1D Gaussian\n","    _1d = _gaussian_window(window_size, sigma=1.5).to(device=device, dtype=dtype)\n","    _2d = _1d.unsqueeze(1) @ _1d.unsqueeze(0)              # outer product → 2D kernel\n","    _2d = _2d.unsqueeze(0).unsqueeze(0)                     # shape (1,1,ws,ws)\n","    window = _2d.expand(channel, 1, window_size, window_size).contiguous()\n","    return window\n","\n","class SSIM_Loss(nn.Module):\n","    \"\"\"\n","    Structural Similarity (SSIM) loss.\n","    Returns 1 - mean(SSIM) over the batch.\n","    \"\"\"\n","\n","    def __init__(self, window_size: int = 11, size_average: bool = True):\n","        super().__init__()\n","        self.window_size = window_size\n","        self.size_average = size_average\n","\n","    def forward(self, img1: torch.Tensor, img2: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Compute SSIM loss between two batches of images [B×C×H×W].\"\"\"\n","\n","        # constants for stability (L = 1.0 since inputs are normalized to [0,1])\n","        C1 = (0.01 ** 2)\n","        C2 = (0.03 ** 2)\n","\n","        batch, channel, height, width = img1.shape\n","        # make Gaussian window\n","        window = _create_window(self.window_size, channel, img1.device, img1.dtype)\n","\n","        # compute means via depthwise conv\n","        mu1 = F.conv2d(img1, window, padding=self.window_size//2, groups=channel)\n","        mu2 = F.conv2d(img2, window, padding=self.window_size//2, groups=channel)\n","\n","        mu1_sq = mu1.pow(2)\n","        mu2_sq = mu2.pow(2)\n","        mu1_mu2 = mu1 * mu2\n","\n","        # compute variances & covariance\n","        sigma1_sq = F.conv2d(img1 * img1, window, padding=self.window_size//2, groups=channel) - mu1_sq\n","        sigma2_sq = F.conv2d(img2 * img2, window, padding=self.window_size//2, groups=channel) - mu2_sq\n","        sigma12   = F.conv2d(img1 * img2, window, padding=self.window_size//2, groups=channel) - mu1_mu2\n","\n","        # SSIM map\n","        num = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n","        den = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n","        ssim_map = num / (den + 1e-12)\n","\n","        if self.size_average:\n","            ssim_val = ssim_map.mean()\n","        else:\n","            # mean per image in batch\n","            ssim_val = ssim_map.view(batch, -1).mean(dim=1)\n","\n","        # loss = 1 – SSIM\n","        return 1 - ssim_val\n","\n","\n","class MSE_Crop_Loss(torch.nn.Module):\n","    def __init__(self):\n","        super(MSE_Crop_Loss, self).__init__()\n","    def forward(self,pred, target, corners):\n","\n","        crop_score = 0\n","\n","        for b in range(len(corners)):\n","            corners_x = corners[b][0:8:2]\n","            corners_y = corners[b][1:8:2]\n","            min_x = min(corners_x)\n","            max_x = max(corners_x)\n","            min_y = min(corners_y)\n","            max_y = max(corners_y)\n","\n","            if min_x<0:\n","                min_x=0\n","            if min_y<0:\n","                min_y=0\n","            if max_x<0:\n","                max_x=0\n","            if max_y<0:\n","                max_y=0\n","            if min_x>IMG_WIDTH:\n","                min_x=IMG_WIDTH\n","            if min_y>IMG_HEIGHT:\n","                min_y=IMG_HEIGHT\n","            if max_x>IMG_WIDTH:\n","                max_x=IMG_WIDTH\n","            if max_y>IMG_HEIGHT:\n","                max_y=IMG_HEIGHT\n","\n","            cropped_tgt = torchvision.transforms.functional.crop(target[b],int(min_y),int(min_x),int(max_y-min_y), int(max_x-min_x))\n","            cropped_pred = torchvision.transforms.functional.crop(pred[b],int(min_y),int(min_x),int(max_y-min_y), int(max_x-min_x))\n","            #cropped_tgt = target[b][min_x:max_x,min_y:max_y]\n","            #cropped_pred = pred[b][min_x:max_x,min_y:max_y]\n","            crop_score += torch.nn.functional.mse_loss(cropped_pred,cropped_tgt)\n","            #crop_score = np.square(np.subtract(cropped_pred,cropped_tgt)).mean()\n","\n","        score = torch.nn.functional.mse_loss(pred,target)\n","\n","        crop_score = crop_score / len(corners)\n","        return 1-(0.9*crop_score + 0.1*score)\n","\n","x = torch.randn(1,3,1920, 1080)\n","y = model(x)\n","\n","aux = y[0,:,:,:].cpu().detach().numpy()*255\n","aux = aux.astype(np.uint8)\n","aux = np.transpose(aux, (1,2,0))\n","\n","make_dot(y.mean(), params=dict(model.named_parameters())).render('Debulr_Model', format=\"png\")\n","\n","model_image = cv.imread('Debulr_Model.png')\n","cv.imwrite(SOURCE_FOLDER+'/Results/Deblur_Model.png',model_image)\n","\n","model= torch.nn.DataParallel(model)\n","model.to('cuda')\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","if TRAIN_TYPE == 0:\n","    loss_function = MSE_Crop_Loss()\n","elif TRAIN_TYPE==3:\n","    loss_function = torch.nn.BCEWithLogitsLoss(reduction='mean')\n","elif TRAIN_TYPE==4:\n","    loss_function = SSIM_Loss()\n","else:\n","    loss_function = torch.nn.MSELoss()\n","\n","# Create Log file\n","with open(training_history_filename, \"w\") as csv_file:\n","    progress_string = 'EPOCH,LOSS,TRAIN_SCORE,VAL_SCORE/n'\n","    csv_file.write(progress_string)\n","\n","\n","best_train_score = 0.0\n","\n","if TRAIN:\n","\n","    for epoch in range(EPOCHS):\n","\n","        #torch.cuda.empty_cache()\n","\n","        #reset running loss\n","        running_loss = 0.0\n","        running_train_score = 0.0\n","        running_val_score = 0.0\n","\n","        #shuffle data list\n","        train_df = train_df.sample(frac=1)    #shuffle dataframe\n","\n","        csv_row = train_df.iloc[:]\n","        train_img_list = list(csv_row['ID'])\n","        train_corners_list = list(csv_row[['cornerTL_x','cornerTL_y','cornerTR_x','cornerTR_y','cornerBL_x','cornerBL_y','cornerBR_x','cornerBR_y']].to_numpy())\n","\n","        # train batches ---------------------------------------------\n","        #iterate through batches\n","        for batch in range(0,len(train_img_list),BATCH_SIZE):\n","\n","            if (batch+BATCH_SIZE<=len(train_img_list)):\n","                batch_img_list = train_img_list[batch:batch+BATCH_SIZE]\n","                batch_corners_list = train_corners_list[batch:batch+BATCH_SIZE]\n","            else:\n","                if len(train_img_list)==1:\n","                    batch_img_list = [train_img_list[0]]\n","                    batch_corners_list = [train_corners_list[0]]\n","                else:\n","                    batch_img_list = train_img_list[batch:-1]\n","                    batch_corners_list = train_corners_list[batch:-1]\n","\n","            if TRAIN_TYPE == 1:\n","                batch_inputs, batch_outputs, batch_corners = yield_training_batch_black_BG(batch_img_list, batch_corners_list)\n","            elif TRAIN_TYPE == 3:\n","                batch_inputs, batch_outputs, batch_corners = yield_training_batch_binary(batch_img_list, batch_corners_list)\n","            else:\n","                batch_inputs, batch_outputs, batch_corners = yield_training_batch(batch_img_list, batch_corners_list)\n","\n","            # Skip batch if no images were processed (i.e. helper returned None or an empty batch)\n","            if batch_inputs is None or batch_inputs.shape[0] == 0:\n","                continue\n","\n","            #print(torch.cuda.memory_summary(device=None, abbreviated=False))\n","\n","            #read each image and augment\n","            batch_preds = model(batch_inputs)\n","\n","            #reset the gradients\n","            optimizer.zero_grad()\n","\n","            #claculate loss for batch\n","            if TRAIN_TYPE == 0:\n","                loss = loss_function(batch_preds, batch_outputs.cuda(),batch_corners)\n","            else:\n","                loss = loss_function(batch_preds, batch_outputs.cuda())\n","\n","\n","            #calculate score for batch\n","            train_score = 1-loss\n","\n","            #backward pass\n","            loss.backward()\n","\n","            #step the optimizer ...?\n","            optimizer.step()\n","\n","            running_loss += loss\n","            running_train_score += train_score\n","\n","\n","\n","\n","        # validation batches ---------------------------------------------\n","        #shuffle data list\n","        val_df = val_df.sample(frac=1)    #shuffle dataframe\n","\n","        csv_row = val_df.iloc[:]\n","        val_img_list = list(csv_row['ID'])\n","        val_corners_list = list(csv_row[['cornerTL_x','cornerTL_y','cornerTR_x','cornerTR_y','cornerBL_x','cornerBL_y','cornerBR_x','cornerBR_y']].to_numpy())\n","\n","        #iterate through batches\n","        for batch in range(0,len(val_img_list),BATCH_SIZE):\n","            if (batch+BATCH_SIZE<len(val_img_list)):\n","                batch_img_list = val_img_list[batch:batch+BATCH_SIZE]\n","                batch_corners_list = val_corners_list[batch:batch+BATCH_SIZE]\n","            else:\n","                if len(val_img_list)==1:\n","                    batch_img_list = [val_img_list[0]]\n","                    batch_corners_list = [val_corners_list[0]]\n","                else:\n","                    batch_img_list = val_img_list[batch:-1]\n","                    batch_corners_list = val_corners_list[batch:-1]\n","\n","            if TRAIN_TYPE == 1:\n","                batch_inputs, batch_outputs, batch_corners = yield_training_batch_black_BG(batch_img_list, batch_corners_list)\n","            elif TRAIN_TYPE == 3:\n","                batch_inputs, batch_outputs, batch_corners = yield_training_batch_binary(batch_img_list, batch_corners_list)\n","            else:\n","                batch_inputs, batch_outputs, batch_corners = yield_training_batch(batch_img_list, batch_corners_list)\n","\n","            #read each image and augment\n","            batch_preds = model(batch_inputs)\n","\n","            #calculate score for batch\n","            if TRAIN_TYPE == 0:\n","                val_score = 1-loss_function(batch_preds, batch_outputs.cuda(), batch_corners)\n","            else:\n","                val_score = 1-loss_function(batch_preds, batch_outputs.cuda())\n","\n","\n","            running_val_score += val_score#.item()\n","\n","        # Writes progress to csv file\n","        with open(training_history_filename, \"a\") as csv_file:  # append mode\n","            progress_string = str(epoch)+','+str(running_loss.item())+','+str(running_train_score.item())+','+str(running_val_score.item())+'/n'\n","            csv_file.write(progress_string)\n","\n","        print('=========================================================')\n","        print('Epoch '+ str(epoch))\n","        print('Loss ' + str(running_loss.item()))\n","        print('Train Score '+ str(running_train_score.item()))\n","        print('Validation Score '+ str(running_val_score.item()))\n","        print('=========================================================')\n","\n","\n","        if running_train_score.item()>best_train_score:\n","            model_name = 'Best_Deblurr_model'\n","\n","            if DNN_TYPE==0:\n","                if TRAIN_TYPE==3:\n","                    model_to_save=EDSR_binary()\n","                else:\n","                    model_to_save=EDSR()\n","            else:\n","                model_to_save=UNet()\n","\n","            model_to_save.load_state_dict(model.module.state_dict())\n","            model_to_save.to('cuda')\n","            model_scripted = torch.jit.script(model_to_save)\n","            model_scripted.save(SOURCE_FOLDER+'/Results/'+model_name+'.pt')\n","            #torch.save(model.module.state_dict(),SOURCE_FOLDER+'/LineFeatures_Results/'+model_name+'.pt')\n","            best_train_score=running_train_score.item()\n","\n","print('DONE')\n","\n","\n","if TEST:\n","    # Load the best model from file (update path if necessary)\n","    model_path = os.path.join(SOURCE_FOLDER, 'Results', '16.04.2025.pt')\n","    model_instance = torch.load(model_path,weights_only=False)\n","    model_instance.to('cuda')\n","    model_instance.eval()\n","    test_dir = os.path.join(SOURCE_FOLDER, 'Lens_Dataset', 'INPUTS')  # Set your test directory\n","    filelist = [f for f in os.listdir(test_dir) if f.endswith('.png')]\n","\n","    # Display predictions for up to 10 random test images\n","    for i in range(min(10, len(filelist))):\n","        r = random.randrange(0, len(filelist))\n","        frame = cv.imread(os.path.join(test_dir, filelist[r]))\n","        # Resize and normalize for network input\n","        frame = cv.resize(frame, (1920, 1080)) / 255.0\n","        frame_T = np.transpose(frame, (2, 0, 1))\n","        np_tensor = np.expand_dims(frame_T, axis=0).astype(np.float32)\n","        input_tensor = torch.tensor(np_tensor).cuda()\n","        with torch.no_grad():\n","            preds = model_instance(input_tensor)\n","        # For SSIM mode, apply sigmoid to force outputs in [0,1]\n","        if TRAIN_TYPE == 4:\n","            preds = torch.sigmoid(preds)\n","        aux = preds[0, :, :, :].cpu().detach().numpy() * 255\n","        aux = aux.astype(np.uint8)\n","        output_image = np.transpose(aux, (1, 2, 0))\n","        imshow_cv2(output_image, title=f\"Prediction for {filelist[r]}\", resize_factor=0.5)"]},{"cell_type":"code","source":["!ls  /content/Deblur/Results/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BGpqnAM5Tbo","executionInfo":{"status":"ok","timestamp":1744895833434,"user_tz":-60,"elapsed":116,"user":{"displayName":"João Brito","userId":"12639566270386605316"}},"outputId":"2c7bb1ee-46a5-4db4-8225-0735f4ce96c9"},"id":"7BGpqnAM5Tbo","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16.04.2025.pt  Best_Deblurr_model.pt  Deblur_Model.png\tlog.csv  Pytorch_0.pt\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["bVV35ZRWhLT7"],"machine_shape":"hm"},"accelerator":"GPU","language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}